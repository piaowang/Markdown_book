sudo的在英语里的意思是switch user and do something．在Linux系统上，你需要root权限来安装和卸载软件包。sudo可以临时将你的用户ID切换为root。

# 返本还源

问题：

* python中当我们导入一个模块，是如何做到函数的调用，是不是存在一个函数表？

## 二进制



## 数，以及对数据性质的思考

算数，算的是数， 算术只是把算当成一个基数。

信息是有意义的数据，数据不是数，而是数的系列；数据的内聚特性表明它由一系列有相互关系的数据构成，其外延的特性表明他可以与其他数的系列建立新的抽象关系。

为什么用系列？这里的系列是对数据的构成元素（多个二进制位）之间存在着的关系的简单谓称。数，与数据之间存在不确定的函数映射关系，即是：

>   A这个数在 "ASCII字符集“它是由于”1000001“这七个二进制数形成的组合关系，这个组合关系是强制的，如果换了一个组合就不是代表A而是其他了。如果说A是“1000001”的组合关系，那么B必然也可以说是A的组合关系的外延，
>
>   B=f(A)，在ASCII字符集中，B=A+1，但是如果在其他系统，比如密码系统，这个两个字符的关系而言，f（）就可以是另外一个函数，而不是A+1。
>
>   数，与数据之间存在不确定的函数映射关系，这就是为什么叫数的系列，而不是序列。序列，数学上是被排成一列的[对象](https://baike.baidu.com/item/%E5%AF%B9%E8%B1%A1/17158)（或[事件](https://baike.baidu.com/item/%E4%BA%8B%E4%BB%B6/33582)）；这样每个[元素](https://baike.baidu.com/item/%E5%85%83%E7%B4%A0/9563210)不是在其他元素之前，就是在其他元素之后。这里，元素之间的顺序非常重要。

硬件系统以及其背后的逻辑基础都是基于数的概念；软件系统，例如语言、开发工具等等都是基于数据的概念。由此提出一个很重要的问题：

> 我们要操作的数据是什么？
>
> 按：目前而言，是各种别人给出的数据，充满了各种类型。

* 可计算的数据类型

1. 面向交互型式：设备与设备之间，传输总线带宽为标准
2. 交互行为：控制与被控制，指令、逻辑和操作数


# TCP-IP



# 计算机的综合

首先要划出一个“知识的范围”，精通一门学问所必知必会的知识都在这个范围内，其次是掌握该范围内每个知识点中“基础中的基础知识”。最后是能独当一面的“目标”，即**掌握了这些知识可以做什么。**

1. **基础中的基础知识（开端）** 

第1章 计算机的三大原则 输入、运算、输出、指令、数据、计算机的处理方式、计算机不断进化的原因 

**三大原则：**

* **计算机是执行输入、运行、输出的机器**
* **程序是指令和数据的集合**
* **计算机的处理方式有时与人的思维习惯不同**：计算机的信息全部用数字表示

输入、处理和输出三者不可缺失。

指令：控制计算机输入、运行、输出的命令；；把想计算机发出的指令一条条列出了就得到程序。

计算机对文字、颜色的处理都是内部先把文字转换成对应的数字再做处理，这样的数字叫做“字符编码”

要理解一门技术，首先去分析它的指令和数据规范是什么



2. **知识的范围** 

   编程 

   * 第4章 程序像河水一样流动着 流程的种类、流程图、结构化编程、中断、事件驱动 

   顺序 、分支、循环；

   流程图就是用几个图形表示程序的各个部分，有开始结束的钝角矩形、菱形表示分支、矩形宝石处理，还有有角的线表示数据的流动。

   结构化编程的首要就是放弃跳转指令，全部使用顺序、循环、分支来书写

   中断意思是程序流程突然的跳转到程序的特定地方

   事件驱动是根据动作来写程序，事件即是用户在应用程序中点击鼠标或敲击键盘这样的操作

   ​

   ​

   * 第5章 与算法成为好朋友的七个要点 辗转相除法、埃斯托斯特尼筛法、鸡兔同笼问题、线性搜索、哨兵 

     算法是处理问题的处理流程，分步执行处理。步骤有限而且明确。有了直觉就不是算法，算法是机械的，不需要动脑筋。

     辗转相除法：计算最大公约数

     哨兵：指的是一种含有特殊值的数据，可以用来标识数据的结尾等。例如，字符串的末尾用0标识，链表的末尾用-1标识。不用再每次判断是不是到结尾了，只有发现得到哨兵了就是没有需所需的。

     ​

   第6章 与数据结构成为好朋友的七个要点 变量、数组、栈、队列、结构体、自我引用的结构体、列表、二叉树 

   变量是数据的容器，按所存储的数据大小分配一块内存；现在的内存空间都是论M的，指定是不现实的。现在都是由操作系统从尚未分配的内存空间中划出一部分给变量。

   若干数据直线排列起来的数据结构叫数组，即是连**续分配一块特定大小的内存空间**；为了应对超多数量的值，无法一一给予变量定义，通过数组可以好好安排。

   数据的堆积是多种多样的，有的像树，有的像山，对应的可能就是现实中的各种情况。

   ​

   栈——LIFO，后进先出；队列——FIFO，先进先出。

   ​

   第7章 成为会使用面向对象编程的程序员吧 类、可维护性、建模、UML、消息传递、继承、封装、多态 

   ​

3. **目标** 

   第12章 SE负责监管计算机系统的构建 瀑布模型、文档、审核、设计方法、信息化、设备利用率 读完本书，便可了解有关计算机的“基础中的基础知识”，“知识范围”及“目标”






运算器、控制器、存储器、输入、输出

系统单元（CPU、内存、主板相关元件）

储存单元

输入、输出单元

子网掩码中不是1的部分用来确定有多少台主机；网关即是路由器的IP地址，它是通向因特网世界的入口。数据发送过程中会被加载目的地址，路由器会查看附加在数据上的IP地址中的网络地址，如果不是LAN就会把它发送到LAN之外。路由器有一张“路由表”，记载世界范围内的LAN的路由器交换信息（当然是只记住相邻的路由器的路径）——把数据发到哪个路由器。

但能够标识作为数据最终接受者的网卡，还是MAC地址。于是计算机中加入了IP地址到MAC地址的转换，这叫ARP（地址解释协议）。

TCP的三次握手，第一次是确定可以传输，第二次是进行数据传输，第三次是结实传输。

# 程序设计语言

计算机系统上的实现语言，其本质是：找到数据

数据和行为是必须明确的



# 杂项

XML是标记语言即是通过标签为数据赋予意义的语言；HTML是超文本标记语言。

XML 被设计为传输和存储数据，其焦点是数据的内容。

HTML 被设计用来显示数据，其焦点是数据的外观。

HTML 旨在显示信息，而 XML 旨在传输信息。XML是给计算机看的，HTML是给人看的。

Web应用开发可以说是目前软件开发中最重要的部分。Web开发也经历了好几个阶
段：

1. 静态Web页面：由文本编辑器直接编辑并生成静态的HTML页面，如果要修改
  Web页面的内容，就需要再次编辑HTML源文件，早期的互联网Web页面就是
  静态的；
2. CGI：由于静态Web页面无法与用户交互，比如用户填写了一个注册表单，静
  态Web页面就无法处理。要处理用户发送的动态数据，出现了Common
  Gateway Interface，简称CGI，用C/C++编写。
3. ASP/JSP/PHP：由于Web应用特点是修改频繁，用C/C++这样的低级语言非常
  不适合Web开发，而脚本语言由于开发效率高，与HTML结合紧密，因此，迅
  速取代了CGI模式。ASP是微软推出的用VBScript脚本编程的Web开发技术，
  而JSP用Java来编写脚本，PHP本身则是开源的脚本语言。
  廖雪峰 JavaScript Python Git 教程
  665 Web开发
4. MVC：为了解决直接用脚本语言嵌入HTML导致的可维护性差的问题，Web应
  用也引入了Model-View-Controller的模式，来简化Web开发。ASP发展为
  ASP.Net，JSP和PHP也有一大堆MVC框架。
  目前，Web开发技术仍在快速发展中，异步开发、新的MVVM前端技术层出不穷。
  Python的诞生历史比Web还要早，由于Python是一种解释型的脚本语言，开发效率
  高，所以非常适合用来做Web开发。
  Python有上百种Web开发框架，有很多成熟的模板技术，选择Python开发Web应
  用，不但开发效率高，而且运行速度快。



控制单元**（Control Unit）

**寄存器**（Register），是[中央处理器](https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%A4%AE%E8%99%95%E7%90%86%E5%99%A8)内的其中组成部分。存储数据的地方 ，**寄存器是有限存贮容量的高速存贮部件，它们可用来暂存指令、[数据](https://zh.wikipedia.org/wiki/%E6%95%B8%E6%93%9A)和[地址](https://zh.wikipedia.org/w/index.php?title=%E4%BD%8D%E5%9D%80&action=edit&redlink=1)。**在中央处理器的控制部件中，包含的寄存器有[指令寄存器](https://zh.wikipedia.org/wiki/%E6%8C%87%E4%BB%A4%E5%AF%84%E5%AD%98%E5%99%A8)（IR）和[程序计数器](https://zh.wikipedia.org/wiki/%E7%A8%8B%E5%BA%8F%E8%A8%88%E6%95%B8%E5%99%A8)。在中央处理器的算术及逻辑部件中，包含的寄存器有[累加器](https://zh.wikipedia.org/wiki/%E7%B4%AF%E5%8A%A0%E5%99%A8)。

解释一下什么是编译器。前面我们说过，因为计算机没法理解人类语言，我们需要用机器指 令来编写程序，我们现在有了高级编程语言，不必使用麻烦的机器指令，这并不是因为计算机学会了人类语言，而是因为我们请了一位翻译。简单地说，它能够把高 级语言翻译成机器指令，既使我们不用再做那些机械劳动，也能满足机器们的冰冷胃口，这个翻译就是编译器，它本身也是一套程序。

然而，如果我们真正翻开TAOCP读一读，就不难理解这是为什么。我觉得，对于算法的研究，可以分成三层境界。第一层是分析算法的复杂度，这是计算机专业的大学生普遍掌握的技能，达到这个境界，可以说是入了算法的门；第二层境界是改进算法的复杂度，在分析之后继续思考，想办法去降低它，这就可以算是懂算法了；第三层境界，就是寻找算法的最优复杂度，不但要改进它，而且要改到什么程度呢？



显示字符的时候需要根据当前字体设置，用”Hello world!"的每个字符的Unicode值去计算字体内对应的字符索引，根据索引获取字模。

根据字模来绘制字符图形，用当前字体颜色填充，做字体边缘平滑，生成包含字符的RGB32位图

把RGB32位图复制到console窗口对应的frame buffer

操作系统的图形引擎把窗口的frame buffer渲染到屏幕对应的显存内的frame buffer

显卡根据显存buffer 生成信号给显示器，显示器根据信号调整屏幕上每个像素的颜色和亮度。



# 数据结构

* 栈 数据堆积像山
* 队列 排成队
* 链表 任意改变排列顺序
* 二叉树 数据分两列

# 算法

算法即是解决既定问题的步骤，可以用流程图解释算法的步骤。

流程可以分几部分：初始化——循环处理——收尾处理；然后在此基础上细分

* 辗转相除法

  ```
  # -*- coding:utf-8 -*-
  def gcd(a, b):
      if a < b:
          a, b = b ,a
          #print ("a= %s ",a)
      while b :
          a,b = b , a%b
      return a

  print gcd(8,12)
  ```





* **埃拉托斯特尼筛法**

  ```python 
  查找素数
  给出要筛数值的范围n，先用2去筛，即把2留下，把2的倍数剔除掉；再用下一个质数，也就是3筛，把3留下，把3的倍数剔除掉；接下去用下一个质数5筛，把5留下，把5的倍数剔除掉；不断重复下去......。
  def eratosthenes(n):
      P = [i for i in range(2, n+1)] #列表生成式
      p = 0
      while True:
          for i in P[p + 1:]:
              if i % P[p] == 0:
                  P.remove(i)
          if P[p]**2 >= P[-1]:
              break
          p += 1
      return P

  if __name__ == "__main__":
      print (eratosthenes(10))
  ```

  * 顺序查找

  从列表中的第一个项目开始，我们按照基本的顺序排序，简单地从一个项移动到另一个项，直到找到我们正在寻找的项或遍历完整个列表。如果我们遍历完整个列表，则说明正在搜索的项不存在。

  ```
  def sequentialSearch(alist, item):
          pos = 0
          found = False

          while pos < len(alist) and not found:
              if alist[pos] == item:
                  found = True
              else:
                  pos = pos+1

          return found

  testlist = [1, 2, 32, 8, 17, 19, 42, 13, 0]
  print(sequentialSearch(testlist, 3))
  print(sequentialSearch(testlist, 13))
  ```

* 二分查找（顺序表）

二分查找从中间项开始，而不是按顺序查找列表。 如果该项是我们正在寻找的项，我们就完成了查找。 如果它不是，我们可以使用列表的有序性质来消除剩余项的一半。如果我们正在查找的项大于中间项，就可以消除中间项以及比中间项小的一半元素。如果该项在列表中，肯定在大的那半部分。

```python
def binarySearch(alist, item):
        first = 0
        last = len(alist)-1
        found = False

        while first<=last and not found:
            midpoint = (first + last)//2
            if alist[midpoint] == item:
                found = True
            else:
                if item < alist[midpoint]:
                    last = midpoint-1
                else:
                    first = midpoint+1

        return found

testlist = [0, 1, 2, 8, 13, 17, 19, 32, 42,]
print(binarySearch(testlist, 3))
print(binarySearch(testlist, 13))
```

* 哈希查找（比较难，看不太懂，完成其他再来.9/12）
* 冒泡排序

冒泡排序需要多次遍历列表。它比较相邻的项并交换那些无序的项。每次遍历列表将下一个最大的值放在其正确的位置。实质上，每个项“冒泡”到它所属的位置。

Figure 1 展示了冒泡排序的第一次遍历。阴影项正在比较它们是否乱序。如果在列表中有 n 个项目，则第一遍有 n-1 个项需要比较。重要的是要注意，**一旦列表中的最大值**是一个对的一部分，它将不断地被移动，直到遍历完成。

![5.7.冒泡排序.figure1](https://facert.gitbooks.io/python-data-structure-cn/5.%E6%8E%92%E5%BA%8F%E5%92%8C%E6%90%9C%E7%B4%A2/5.7.%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/assets/5.7.%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F.figure1.png)



  

第一轮把最大的放在了最后，第二轮就会把第二大的也放到导数第二，如此循环。

```
def bubbleSort(alist):
    for passnum in range(len(alist)-1,0,-1): #range(n,0,-1)倒序，间隔为1
        for i in range(passnum):             #取上面range的第一个进行迭代，从0开始
            if alist[i]>alist[i+1]:            到比最后一个小1，为了给i+1做准备
                temp = alist[i]
                alist[i] = alist[i+1]
                alist[i+1] = temp

alist = [54,26,93,17,77,31,44,55,20]
bubbleSort(alist)
print(alist)
```





* 快速排序（9/13，看不懂，甚至不知道懂了什么）

选择一个枢纽值，把list分成两块，一块在枢纽值的左边，另一块在右边

```
def quickSort(alist):
   quickSortHelper(alist,0,len(alist)-1)  #传入三个参数

def quickSortHelper(alist,first,last):
   if first<last:  # 0 当然小于list长度减一 ，即是0 < 8

       splitpoint = partition(alist,first,last) # 跳到另一个函数，传入(list，0 ,8)

       quickSortHelper(alist,first,splitpoint-1)
       quickSortHelper(alist,splitpoint+1,last)


def partition(alist,first,last): # 现在个里是[54,26,93,17,77,31,44,55,20]，0 ，8
   pivotvalue = alist[first]     # 取list第一个值作为枢纽值

   leftmark = first+1           # 左标记当然是第二个数值
   rightmark = last             #右标记是倒数第最后一个

   done = False
   while not done:# 即是true

       while leftmark <= rightmark and alist[leftmark] <= pivotvalue:
           leftmark = leftmark + 1
           #1. while 26<=20 ,跳过


       while alist[rightmark] >= pivotvalue and rightmark >= leftmark:
           rightmark = rightmark -1
           # 1. while2 20  >=54, 跳过


       if rightmark < leftmark:
          # 1 pass 20 < 26
           done = True
           # done 变true，不自信
       else:
           temp = alist[leftmark]
           alist[leftmark] = alist[rightmark]
           alist[rightmark] = temp
    #上面的if 为真的时候，就是右边小于左边，
   temp = alist[first]
   alist[first] = alist[rightmark] #需要把枢纽值换到右边
   alist[rightmark] = temp


   return rightmark

alist = [54,26,93,17,77,31,44,55,20]
quickSort(alist)
print(alist)
```



# 字符

字符**编码**则是指**字符在传输过程当中用于表示字符的二进制序列**。文本数据可由各种字符构成，每个字符分配了一个数字，成为字符编码。定义了应该把哪个编码分配给哪个字符的字符编码体系叫做字符集。加密的基本手段还是字符编码的变换，将构成明文的每个字符的编码分别转换为其他的数字。

加密分为第一种对称加密，大家都有密匙，但是密匙的保存可能是问题；第二种，公开密匙，机密是公开的，但是解密是私人拥有的。数字签名即是按步骤生成的信息摘要——一个数值，对明文的所有字符的编码进行某种操作得到的数值。数字签名用来证明这是真实的，而不是伪造的。

一门新语言绝非只是一套语法规则，而是一系列配套的工具加上语法规则。

MB/mb/Mbps有区别吗？这里来说一说流量带宽单位Mbps、Mb/s、MB/s的区别。相同的道理可以区别GB/Gbps。www.ctohome.com的所有流量都是GB为单位的，不是Gbps.

**1、我们经常听到某某IDC提供的服务器接入带宽是10M独享，或者100M共享之类的数据。这里的10M、100M到底是什么概念呢？**

所谓 10M 带宽，其实是指 10Mbps （兆比特），即 1.25MB/s，但这只是理论上的速度，实际上，还要再减去损耗。按这个说法10M的带宽最快下载速度是1.25MB/s，100M的带宽最快下载速度是12.5MB/s。

**2、在上面我们接触到了MB/s，那MB/s和Mb/s有什么区别哪？**

MB/s 的含义是兆字节每秒，Mb/s的含义是兆比特每秒，前者是指每秒传输的字节数量，后者是指每秒传输的比特位数。二者是完全不同的。Byte是字节 数，bit是位数，在计算机中每八位为一字节，也就是1Byte＝8bit，是1：8的对应关系。因此1MB/s等于8Mb/s。因此在在书写单位时一定 要注意B字母的大小写，此时B字母的大小真可以称为失之毫厘，谬以千里。

在数据传输率上官方数据中(如电信部门)一般采用Mb/s或Kb/s为单位。
而下载软件(如IE、迅雷、快车)一般采用MB/s或KB/s为单位。

# 内存



在早期的计算机中，程序是直接运行在物理内存上的。换句话说，就是程序在运行的过程中访问的都是物理地址，CPU读取的数据都是从内存来的，内存内的数据则是从输入单元传输进来的，CPU处理完也要协会内存然后传输给输出单元。

内存管理无非就是想办法解决上面的问题，如何使进程的地址空间隔离，如何提高内存的使用效率，如何解决程序运行时的重定位问题？

存储管理主要解决下面两个问题:

1.地址的转换

2.硬盘虚拟内存

* **地址转换**

现在的内存管理方法就是在进程和物理内存之间引入了虚拟内存这个概念。

（1）虚拟内存位于程序和物理内存之间，进程只能看见虚拟内存，再也不能直接访问物理内存。

（2）每个程序都有自己独立的进程地址空间，这样就做到了进程隔离。这里的进程地址空间是指虚拟地址。

（3）既然是虚拟地址，也就是虚的，不是现实存在的地址空间。

既然我们在进程和物理地址空间之间增加了虚拟地址，那么就要解决怎么从虚拟地址映射到物理地址，因为进程最终肯定是运行在物理内存中的，主要有分段和分页两种技术。

Linux将为每个进程都分配4G的虚拟内存空间，其中位于高地址（3G-4G）的1G空间给内核用，称为内核空间，另外的3G（0-3G）都是它一个人独占的，称为用户空间，其中内核空间是所有进程共享的，于是，从具体进程的角度来看，每个进程可以拥有4G字节的虚拟空间。

因为进程运行时需要物理地址，所以虚拟内存空间必须映射为物理地址。内核空间映射到物理内存中的某一块区域，进程空间映射到物理内存的其它区域。但是这些区域在物理区域在不一定是连续的，而是通过页表将它们联系起来。

# 硬盘



硬盘：硬盘的0柱面、0磁头、1扇区称为主引导扇区（也叫主引导记录MBR），该记录占用512个字节;MBR由三部分构成：

　　1．主引导程序代码，占446字节

　　2．硬盘分区表DPT，占64字节（只能存储4个主分区）

　　3．主引导记录结束标志AA55H

分区是硬盘必要的一种逻辑结构，定义了数据储存的范围，硬盘不能直接用于存储数据，必须对硬盘进行分区后，将数据存储在分区中。

磁盘分区包括：主分区，扩展分区

1、主分区

主分区，也称为主磁盘分区，主分区中不能再划分其他类型的分区。一个硬盘主分区至少有1个，最多4个（DPT只有4个表项）。

激活的主分区是硬盘的启动分区，他是独立的，也是硬盘的第一个分区，windows系统一般是C驱。

2、扩展分区

分出主分区后，其余的部分可以分成扩展分区但扩展分区是不能直接使用的，他是以逻辑分区的方式来使用的，所以说扩展分区可分成若干逻辑分区。它们的关系是包含的关系，所有的逻辑分区都是扩展分区的一部分。

3、逻辑分区

逻辑分区是硬盘上一块连续的区域，不同之处在于，每个主分区只能分成一个驱动器，每个主分区都有各自独立的引导块，可以用fdisk设定为启动区。一个硬盘上最多可以有4个主分区，而扩展分区上可以划分出多个逻辑驱动器。这些逻辑驱动器没有独立的引导块，不能用fdisk设定为启动区。

下面是硬盘的分区表的解释，总64位，16位位一个分区，一下死16位存储的数据的解析。

![分区表](H:\Markdownbook\image\分区表.png)



# 文件

操作系统是一个魔术师，其提供给用户的就是各种幻想：抽象。对于磁盘来说，操作系统提供给用户的帮助就是在磁盘外面包裹一层容易使用的抽象，用户直接与这层抽象打交道，而无需了解磁盘的技术细节。在操作系统中，这层为磁盘提供的抽象就是：**文件系统。**

![文件系统](H:\Markdownbook\image\文件系统.jpg)



我按：文件系统相当于一种解释，当用户输入文件路径或文件，就会通过文件系统解释出文件地址（包含了内容，格式日期等等信息）

* 1）文件系统使得用户能够很方便的使用磁盘：将用户从数据存放的细节中解放出来，用户不需要知道内容存放在什么地方，也不需要知道如何存放，更不需要知道磁盘到底是如何工作的。
* （2）简单地说，文件系统将其接触的磁盘物理特性转换为用户看到的路径名和文件名。用户对磁盘进行访问只需要给出文件名和路径名即可，而无需知道磁柱、磁道、扇面、数据块等信息。
* （3）文件系统的主要特性就是存储大量的信息，多个进程可以同时访问一个文件，进程结束也不会影响文件的持续存在。

![文件系统](H:\Markdownbook\image\文件系统.png)



**对磁盘扇区不同的组织方式形成了不同的文件系统类型**

ext2,3,4 ： linux中常用的文件系统

   FAT ：Windows XP 操作系统采用的文件系统

   NTFS ：Windows 7/XP 操作系统采用的文件系统

   PROC : 虚拟的进程文件系统

   ISO9660 ：大部分光盘所采用的文件系统

   XFS ：由SGI开发的先进的日志文件系统，支持超大容量文件

   JFS ：IBM的AIX使用的日志文件系统   



* **linux 的ext4的解析：**

![ext4](H:\Markdownbook\image\ext4.png)

data block：实际数据存储的地方

引导块（引导扇区）：如果是可启动分区，则里面放的是操作系统引导代码。

超级块（super block）：这个分区文件系统的整体信息，包括inode/block总量和大小、使用量、剩余量，文件系统相关信息。

 文件系统一开始就将inode与block规划好了，除非重新格式化，否则inode和block固定后就不会在发生变化。每个inode与block都有自己的编号，inode就是记录文件的属性，一个文件占用一个inode，同时记录此文件数据所在的block编号。block则是实际记录文件的内容，若文件过大则会占用多个block。

其实文件名是在目录文件中。那么目录文件又是什么结构呢，目录文件的结构非常简单，就是一系列目录项的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。

![目录和Inode的使用](H:\Markdownbook\image\目录和Inode的使用.png)



总的访问时间 Taccess = 寻址时间 Tavg seek + 旋转时间 Tavg rotation + 传输时间 Tavg transfer

- 寻址时间 Tavg seek 因为物理规律的限制，一般是 3-9 ms
- 旋转延迟 Tavg rotation 取决于硬盘具体的转速，一般来说是 7200 RPM
- 传输时间 Tavg tranfer 就是需要读取的扇区数目



固态硬盘中分成很多的块(Block)，每个块又有很多页(Page)，大约 32-128 个，每个页可以存放一定数据（大概 4-512KB），页是进行数据读写的最小单位。但是有一点需要注意，对一个页进行写入操作的时候，需要先把整个块清空（设计限制），而一个块大概在 100,000 次写入之后就会报废。

**路径**

绝对路径：从根目录/开始

相对路径：从当前目录开始（不是从/开始,以当前目录为根目录）

假定当前目录为/home

要跳转到/usr/bin目录

绝对路径：cd /usr/bin

相对路径:  cd ../usr/bin

注：. .表示上一级目录目录



**局部性的思路很简单：**

- 时间局部性(Temporal Locality): 如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。程序循环、堆栈等是产生时间局部性的原因。
- 空间局部性(Spatial Locality): 在最近的将来将用到的信息很可能与现在正在使用的信息在空间地址上是临近的
- 顺序局部性(Order Locality): 在典型程序中，除转移类指令外，大部分指令是顺序进行的。顺序执行和非顺序执行的比例大致是5:1。此外，对大型数组访问也是顺序的。指令的顺序执行、数组的连续存放等是产生顺序局部性的原因。





这里就涉及到一个技术：缓存。缓存可以看作是把**大且缓慢的设备中的数据的一部分拿出来存储到其中的更快的存储设备**。在金字塔式存储体系[3]中，每一层都可以看作是下一层的缓存。利用局部性原理，程序会更倾向于访问第 k 层的数据，而非第 k+1 层，这样就减少了访问时间。

![](http://wdxtub.com/images/14612615839808.jpg)







![](http://wdxtub.com/images/14612508854709.jpg)



一台64M字节的内存，那没就有0到64M个地址（1M= 100万个），怎么多地址是没办法指定的，用变量的方法替代。





# 链接器

**编译是指编译器读取源程序（字符流），对之进行词法和语法的分析，将高级语言指令转换为功能等效的汇编代码。**源文件的编译过程包含两个主要阶段：

第一个阶段是**预处理阶段**，在正式的编译阶段之前进行。预处理阶段将根据已放置在文件中的预处理指令来修改源文件的内容。主要是以下几方面的处理：

1. 宏定义指令，如 `#define a b` 这种伪指令，预编译所要做的是将程序中的所有 `a` 用 `b` 替换，但作为字符串常量的 `a` 则不被替换。还有 `#undef`，则将取消对某个宏的定义，使以后该串的出现不再被替换
2. 条件编译指令，如 `#ifdef`, `#ifndef`, `#else`, `#elif`, `#endif`等。这些伪指令的引入使得程序员可以通过定义不同的宏来决定编译程序对哪些代码进行处理。预编译程序将根据有关的文件，将那些不必要的代码过滤掉
3. 头文件包含指令，如 `#include "FileName"` 。该指令将头文件中的定义统统都加入到它所产生的输出文件中，以供编译程序对之进行处理
4. 特殊符号，预编译程序可以识别一些特殊的符号。例如在源程序中出现的 `LINE` 标识将被解释为当前行号（十进制数），`FILE` 则被解释为当前被编译的C源程序的名称。预编译程序对于在源程序中出现的这些串将用合适的值进行替换

第二个阶段编译、优化阶段，编译程序所要作得工作就是通过词法分析和语法分析，在确认所有的指令都符合语法规则之后，将其翻译成等价的中间代码表示或汇编代码。

汇编实际上指汇编器(as)把汇编语言代码翻译成目标机器指令的过程。目标文件中所存放的也就是与源程序等效的目标的机器语言代码。目标文件由段组成。通常一个目标文件中至少有两个段：

- 代码段：该段中所包含的主要是程序的指令。该段一般是可读和可执行的，但一般却不可写
- 数据段：主要存放程序中要用到的各种全局变量或静态的数据。一般数据段都是可读，可写，可执行的

## 链接基本知识

> 为什么要使用链接器？

有如下两个原因。

- 模块化角度考虑。我们可以把程序分散到不同的小的源代码中，而不是一个巨大的类中。这样带来的好处是可以复用常见的功能/库，比方说 Math library, standard C library.
- 效率角度考虑。改动代码时只需要重新编译改动的文件，其他不受影响。而常用的函数和功能可以封装成库，提供给程序进行调用（节省空间）

> 链接器做了什么？

主要负责做两件事情

**第一步：符号解析 Symbol resolution**

我们在代码中会声明变量及函数，之后会调用变量及函数，所有的符号声明都会被保存在符号表(symbol table)中，而符号表会保存在由汇编器生成的 object 文件中（也就是 `.o` 文件）。符号表实际上是一个结构体数组，每一个元素包含名称、大小和符号的位置。

在 symbol resolution 阶段，链接器会给每个符号应用一个唯一的符号定义，用作寻找对应符号的标志。

**第二步：重定位 Relocation**

这一步所做的工作是把原先分开的代码和数据片段汇总成一个文件，会把原先在 `.o` 文件中的相对位置转换成在可执行程序的绝对位置，并且据此更新对应的引用符号（才能找到新的位置）



# cpu

CPU能直接识别和执行的只有机器语言。CPU由具有ON/OFF开关功能的晶体管构成。

CPU的主要单元，算数逻辑单元（程序运行和逻辑判断），控制单元（协调部件和各单元的工作）

CPU在时钟信号的控制下解释、 执行内存中存储的程序， 按照程序中的指令从内存或 I/O 中把数据输入到 CPU 中， 在 CPU 内部进行运算， 再把运算结果输出到内存或 I/O 中



这里需要注意，处理器能够执行的操作其实是非常有限的，简单来说只有三种：**存取数据、计算和传输控制。****存取数据是在内存和寄存器之间传输数据，进行计算则是对寄存器或者内存中的数据执行算术运算，传输控制主要指非条件跳转和条件分支** 。这也就是为什么汇编代码有固定的 `指令 操作数1 (,操作数2 ,操作数3)` 这样的形式了。

数据的运算在cpu中进行的，cpu内部存储数据的地方——寄存器。但是与I/O的寄存器不同，cpu的不单是可以存储，还能够对数据进行运算。cpu带有什么样的寄存器取决于cpu的类型。

时钟信号是在0或1之间反复变换的电信号

CPU配合着由时钟发生器发出的滴答滴答的时钟信号，从内存中读出指令，然后再依次对其进行解释和执行。

CPU中有个PC（program Counter），负责存储内存地址，该地址指向下一条即将执行的指令。



```
一般说来，一个时钟周期完成的指令数是固定的，所以主频越高，CPU的速度也就越快了。不过由于各种CPU的内部结构也不尽相同，所以并不能完全用主频来概括CPU的性能。但CPU主频的高低可以决定电脑的档次和价格水平。以Pentium 4 2.0为例，它的工作主频为2.0GHz，具体来说，2.0GHz意味着每秒钟它会产生20亿个时钟脉冲信号，每个时钟信号周期为0.5纳秒。而Pentium 4 CPU有4条流水线运算单元，如果负载均匀的话，CPU在1个时钟周期内可以进行4个二进制加法运算。这就意味着该Pentium 4 CPU每秒钟可以执行80亿条二进制加法运算。但如此惊人的运算速度不能完全为用户服务，电脑硬件和操作系统本身还要消耗CPU的资源。但Athlon XP处理器采用了PR标称方式，AMD公开的266MHz前端总线频率的Athlon XP处理器标称频率和实际频率的转换计算公式如下:标称频率=3×实际频率/2-500 实际频率=2×标称频率/3+333 例如，Athlon XP 2100+的实际频率为1733MHz=2×2100/3+333
　　
　　信号数据频率也叫频率信号。通常是由于信号的带宽而起的作用。因此通信信道最大传输速率与信道带宽之间存在着明确的关系，所以人们可以用“带宽”去取代“速率”。例如，人们常把网络的“高数据传输速率”用网络的“高带宽”去表述。因此“带宽”与“速率”在网络技术的讨论中几乎成了同义词。
　　信号时钟频率是指同步电路中时钟的基础频率，它以“若干次周期每秒”来度量，单位是赫兹（Hz）
```

# 异常

异常控制流存在于系统的每个层级，最底层的机制称为**异常(Exception)**，用以改变控制流以响应系统事件，通常是由硬件的操作系统共同实现的。更高层次的异常控制流包括**进程切换(Process Context Switch)**、**信号(Signal)**和**非本地跳转(Nonlocal Jumps)**，也可以看做是一个从硬件过渡到操作系统，再从操作系统过渡到语言库的过程。进程切换是由硬件计时器和操作系统共同实现的，而信号则只是操作系统层面的概念了，到了非本地跳转就已经是在 C 运行时库中实现的了。



**异常 Exception**

这里的异常指的是把控制交给系统内核来响应某些事件（例如处理器状态的变化），其中内核是操作系统常驻内存的一部分，而这类事件包括除以零、数学运算溢出、页错误、I/O 请求完成或用户按下了 ctrl+c 等等系统级别的事件。

具体的过程可以用下图表示：

![img](http://wdxtub.com/images/14613541138958.jpg)

系统会通过异常表(Exception Table)来确定跳转的位置，每种事件都有对应的唯一的异常编号，发生对应异常时就会调用对应的异常处理代码

同步异常：执行某条指令所导致的事件，分为陷阱(Trap)、故障(Fault)和终止(Abort)三种情况。

异步异常：是由处理器外面发生的事情引起的。计时器中断、I/O设备中断

## 进程

进程是计算机科学中最为重要的思想之一，进程才是程序（指令和数据）的真正运行实例。之所以重要，是因为进程给每个应用提供了两个非常关键的抽象：**一是逻辑控制流，二是私有地址空间。**

逻辑控制流通过称为上下文切换(context switching)的内核机制让每个程序都感觉自己在独占处理器。

私有地址空间则是通过称为虚拟内存(virtual memory)的机制让每个程序都感觉自己在独占内存。这样的抽象使得具体的进程不需要操心处理器和内存的相关适宜，也保证了在不同情况下运行同样的程序能得到相同的结果。

### 进程切换 Process Context Switch

这么多进程，具体是如何工作的呢？我们来看看下面的示意图：

![img](http://wdxtub.com/images/14613707308133.jpg)

左边是单进程的模型，内存中保存着进程所需的各种信息，因为该进程独占 CPU，所以并不需要保存寄存器值。而在右边的单核多进程模型中，虚线部分可以认为是当前正在执行的进程，因为我们可能会切换到其他进程，**所以内存中需要另一块区域来保存当前的寄存器值，以便下次执行的时候进行恢复（也就是所谓的上下文切换）**。整个过程中，CPU 交替执行不同的进程，虚拟内存系统会负责管理地址空间，而没有执行的进程的寄存器值会被保存在内存中。切换到另一个进程的时候，会载入已保存的对应于将要执行的进程的寄存器值。



而现代处理器一般有多个核心，所以可以真正同时执行多个进程。这些进程会共享主存以及一部分缓存，具体的调度是由内核控制的，示意图如下：

![img](http://wdxtub.com/images/14613708880333.jpg)

切换进程时，内核会负责具体的调度，如下图所示

![img](http://wdxtub.com/images/14613717282590.jpg)





对于前台进程来说，我们可以在其执行完成后进行回收，而对于后台进程来说，因为不能确定具体执行完成的时间，所以终止之后就成为了僵尸进程，无法被回收并因此造成内存泄露。

这怎么办呢？同样可以利用异常控制流，当后台进程完成时，内核会中断常规执行并通知我们，具体的通知机制就是『信号』(signal)。





# 输入输出

Linux 系统中 IO 的概念是非常有趣的，结合『所有东西都是文件』这个抽象，无论是输入输出重定向，还是挂载不同的设备，甚至是网络编程，都可以由系统输入输出这个统一的模型来进行描述。

I/O管理要达到的目的

操作系统就像一个魔术师，提供一个统一的界面来屏蔽各种输入、输出设备的差异，让用户统一可以通过调用I/O 软件的API 来完成用户input、output的需要，让用户不用去关心具体输入、输出设备的工作原理。

I/O管理的目的有以下两点：

　　（1）屏蔽输入输出设备的差异：提供一个统一的界面来屏蔽输入输出设备的差异

　　（2）在不同设计之间进行数据表示的转换：数据能够在不同设备之间相互转换而无需用户操心

所有的I/O设备均可以分为两个大类：块设备和字符设备。块设备是以数据块为单位存储和传输数据的输入输出设备，如磁盘、光盘、U盘等；而字符设备则是将数据按照字符为单位来存放和传输的设备，如鼠标、键盘、打印机等等。I/O设备本身并不是一个不可分割的整体，而是由不同的部件构成。一般来说，一个I/O设备至少可以分为两部分：**机械部分和电子部分**。机械部分是设备的物理硬件部分，而**电子部分**则是设备的控制器。控制器可以处理多个设备，或者说多个同类的设备可以共用一个控制器。

除了有了I/O的硬件是不够的，毕竟，对于用户来说，直接对硬件进行操作十分困难。我们知道，操作系统的角色是魔术师和管理者，魔术是将不同I/O设备的差异屏蔽，使它们看上去似乎是一样的东西，都具有令人赏心悦目的界面；而管理则是对这些设备进行管理，该独享的独享，该共用的共用，需要缓冲的缓冲，并对设备进行实际的驱动（发出读写命令）。

I/O软件都有以下几层：

（1）用户层I/O软件

（2）设备独立性软件（硬盘之类）

（3）设备驱动程序

（4）中断服务程序

  (5) 硬件

**设备驱动程序**：设备驱动程序顾名思义就是直接驱动I/O设备进行输入或输出操作的软件。它属于与设备控制器直接联系的I/O软件部分，与具体的I/O设备直接相关，并针对每个特定的I/O设备进行优化。

**设备独立性软件**：设备驱动程序并不直接从用户处接收I/O请求，而是通过操作系统软件获得的。操作系统在设计时之所以有这层软件是因为I/O软件的一部分与设备有关，一部分与设备无关。而如果与设备无关，就可以将这部分共用起来，放置在设备驱动程序之上，为用户提供一个统一的I/O界面。

**用户层I/O软件（用户进程）**：设备驱动程序从设备独立的软件层接收I/O请求，而设备独立的软件则从用户或应用软件处接收指令。这时，还差一个发出指令的界面，这个界面就是用户层I/O软件。我们可能大多数都见过在一段C程序中count= write(fd, buffer, nbytes)

　　这一句命令就是用户层I/O软件的一部分，write是一个由高级语言提供的库函数，用户与这个库函数打交道，而这个库函数在编译之后会变成一系列指令，来完成系统调用过程。在接口管理中我们再详细了解。

**普通文件**

普通的文件包含任意数据，应用一般来说需要区分出文本文件和二进制文件。文本文件只包含 ASCII 或 Unicode 字符。除此之外的都是二进制文件(对象文件, JPEG 图片, 等等)。对于内核来说其实并不能区分出个中的区别。

文本文件就是一系列的文本行，每行以 `\n` 结尾，新的一行是 `0xa`，和 ASCII 码中的 line feed 字符(LF) 一样。不同系统用用判断一行结束的符号不同(End of line, EOL)，如：

- Windows & 网络协议:


  ```
   Windows & 网络协议: \r\n (0xd 0xa)
  Carriage return(CR) followed by line feed(LF)xxxxxxxxxx \r\n
  ```

   

  ​

**目录**

目录包含一个链接(link)数组，并且每个目录至少包含两条记录：

- `.`(dot) 当前目录
- `..`(dot dot) 上一层目录

用来操作目录的命令主要有 `mkdir`, `ls`, `rmdir`。目录是以树状结构组织的，根目录是 `/`(slash)。

内核会为每个进程保存当前工作目录(cwd, current working directory)，可以用 `cd` 命令来进行更改。我们通过路径名来确定文件的位置，一般分为绝对路径和相对路径。



接下来我们了解一下**基本的文件操作**：

1. 打开文件：在使用文件之前需要通知内核打开该文件
2. 关闭文件：使用完毕之后同样需要通知内核关闭文件
3. 读取文件：在打开和关闭之间就是读取文件，实际上就是把文件中对应的字节复制到内存中，并更新文件指针。
4. 写入文件：把内存中的数据复制到文件中，并更新文件指针：





元数据是用来描述数据的数据，由内核维护，可以通过 `stat` 和 `fstat` 函数来访问，其结构是

**重定向 **

了解了具体的结构之后，我们来看看内核是如何表示已打开的文件的。其实过程很简单，每个进程都有自己的描述符表(Descriptor table)，然后 Descriptor 1 指向终端，Descriptor 4 指向磁盘文件，如下图所示：

![img](http://wdxtub.com/images/14614963360280.jpg)



# 虚拟内存与动态内存分配

进程是操作系统中最重要的抽象，虚拟内存令这一切成为可能，为什么进程可以使用完整且连续的虚拟地址空间，而不需要关注物理内存呢？

1. 了解物理地址和虚拟地址的区别



物理地址一般应用在简单的嵌入式微控制器中（汽车、电梯、电子相框等），因为应用的范围有严格的限制，不需要在内存管理中引入过多的复杂度。

但是对于计算机（以及其他智能设备）来说，虚拟地址则是必不可少的，通过 MMU(Memory management unit)把虚拟地址(Virtual Address, VA)转换为物理地址(Physical Address, PA)，再由此进行实际的数据传输。大致的过程如下图所示

![img](http://wdxtub.com/images/14615011037796.jpg)

使用虚拟内存主要是基于下面三个考虑：

1. 可以更有效率的使用内存：使用 DRAM 当做部分的虚拟地址空间的缓存
2. 简化内存管理：每个进程都有统一的线性地址空间
3. 隔离地址控件：进程之间不会相互影响；用户程序不能访问内核信息和代码





**拟内存的三个角色**

1. 作为缓存工具

概念上来说，虚拟内存就是存储在磁盘上的 N 个连续字节的数组。这个数组的部分内容，会缓存在 DRAM 中，在 DRAM 中的每个缓存块(cache block)就称为页(page)，如下图所示：

![img](http://wdxtub.com/images/14615017442915.jpg)

就是利用 DRAM 比较快的特性，把最常用的数据换缓存起来。如果要访问磁盘的话，大约会比访问 DRAM 慢一万倍，所以我们的目标就是尽可能从 DRAM 中拿数据。





**作为内存管理工具**

前面提到，每个进程都有自己的虚拟地址空间，这样一来，对于进程来说，它们看到的就是简单的线性空间（但实际上在物理内存中可能是间隔、支离破碎的），具体的映射过程可以用下图表示：

![img](http://wdxtub.com/images/14615040688550.jpg)

在内存分配中没有太多限制，每个虚拟页都可以被映射到任何的物理页上。这样也带来一个好处，如果两个进程间有共享的数据，那么直接指向同一个物理页即可（也就是上图 PP 6 的状况，只读数据）

虚拟内存带来的另一个好处就是可以简化链接和载入的结构（因为有了统一的抽象，不需要纠结细节）



**动态内存分配器**会管理一个虚拟内存区域，称为堆(heap)。

分配器以块为单位来维护堆，可以进行分配或释放。有两种类型的分配器：

- 显式分配器：应用分配并且回收空间（C 语言中的 `malloc` 和 `free`）
- 隐式分配器：应用只负责分配，但是不负责回收（Java 中的垃圾收集）





影响内存利用率的主要因素就是『内存碎片』，分为内部碎片和外部碎片两种。

**内部碎片**

内部碎片指的是对于给定的块，如果需要存储的数据(payload)小于块大小，就会因为对齐和维护堆所需的数据结构的缘故而出现无法利用的空间，例如：

![img](http://wdxtub.com/images/14619426495995.jpg)

内部碎片只依赖于上一个请求的具体模式，所以比较容易测量。



**外部碎片**

指的是内存中没有足够的连续空间，如下图所示，内存中有足够的空间，但是空间不连续，所以成为了碎片：

![img](http://wdxtub.com/images/14619429933039.jpg)





**垃圾回收**

所谓垃圾回收，就是我们不再需要显式释放所申请内存空间了，



# 网络编程

在这个网络成为『必需品』的时代，让我们从最原始的 Socket(套接字)开始，来看看程序是如何通过网络进行『沟通』的。更有意思的是，这一讲我们会介绍如何通过 C 语言从零开始实现自己的服务器程序。

**网络通信是两台计算机上的两个进程之间的通信。**比如，浏览器进程和新浪服务器上的某个Web服务进程在通信，而QQ进程是和腾讯的某个服务器上的某个进程在通信。

用Python进行网络编程，就是在Python程序本身这个进程内，连接别的服务器进程的通信端口进行通信。

IP地址通过物理网卡确定地址和完成分包，进行传输的是TCP协议，通过握手进行确定，并进行掉包检测，还需要确定传输的端口。同时将工作的进程很多，确定唯一目标就需要系统像进程分配端口，进行最后确认地址。

作为服务器，提供什么样的服务，端口号就必须固定下来。由于我们想要访问网页，因此新浪提供网页服务的服务器必须把端口号固定在 80 端口，因为 80 端口是Web服务的标准端口。其他服务都有对应的标准端口号，例如SMTP服务是25端口，FTP服务是21端口，等等。端口号小于1024的是Internet标准服务的端口，端口号大于1024的，可以任意使用。

AF = Address Family 
PF = Protocol Family

```python
作为客户端链接新浪
#!/usr/bin/env python
# -*- coding: utf-8 -*-

'a socket example which get html data from www.sina.com.cn'

import socket

s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
#AF_INET 指定使用IPv4协议，如果要用更先进的IPv6，就指定为 AF_INET6 。 SOCK_STREAM 指定使用面向流的TCP协议，这样，一个 Socket 对象就创建成功，但是还没有建立连接。

# 建立连接:
s.connect(('www.sina.com.cn', 80)) #参数是一个tuple，包含地址和端口号
# 发送数据:
s.send('GET / HTTP/1.1\r\nHost: www.sina.com.cn\r\nConnection: close\r\n\r\n')
# 接收数据:
buffer = []
while True:
    # 每次最多接收1k字节:
    d = s.recv(1024)
    if d:
        buffer.append(d)
    else:
        break
data = ''.join(buffer)
# 关闭连接:
s.close()

header, html = data.split('\r\n\r\n', 1)
print header
# 把接收的数据写入文件:
with open('sina.html', 'wb') as f:
    f.write(html)
```



## 网络协议

TCP是建立可靠连接，并且通信双方都可以以流的形式发送数据。相对TCP，UDP
则是面向无连接的协议。
使用UDP协议时，不需要建立连接，只需要知道对方的IP地址和端口号，就可以直
接发数据包。但是，能不能到达就不知道了。

在不同的 LAN 和 WAN 中传输数据，就要守规矩，这个规矩就是协议。协议负责做的事情有：

- 提供 naming scheme
  - 定义 host address 格式
  - 每个主机和路由器都至少有一个独立的 internet 地址
- 提供 delivery mechanism
  - 定义了标准的传输单元 - packet
  - Packet 包含 header 和 payload
    - header 包括 packet size, source 和 destination address
    - payload 包括需要传输的数据

在这样的协议下，具体的数据传输如下图所示，这里 PH = Internet packet header, FH = LAN frame header（具体名词解释可见参考文末参考资料）：

![img](http://wdxtub.com/images/14619781335872.jpg)



Internet 是 internet 最为著名的例子。主要基于 TCP/IP 协议族：

- IP (Internet Protocal)
  - Provides **basic naming scheme** and unreliable **delivery capability** of packets (datagrams) from **host-to-host**
- UDP (Unreliable Datagram Protocol)
  - Uses IP to provide **unreliable** datagram delivery from **process-to-process**
- TCP (Transmission Control Protocol)
  - Uses IP to provide **reliable** byte streams from **process-to-process** over **connections**

Accessed via a mix of Unix file I/O and functions from **sockets interface**.（很多东西不是很好翻译，用原文比较准确）

- 主机有 32 位的 IP 地址 - 23.235.46.133
  - IPv4 - 32 位地址，IPv6 - 128 位地址
- IP 地址被映射到域名 - 23.235.46.133 映射到 www.wdxtub.com
- 不同主机之间的进程，可以通过 connection 来交换数据

### Internet 连接

客户端和服务器通过连接(connection)来发送字节流，特点是：

- 点对点: 连接一对进程
- 全双工: 数据同时可以在两个方向流动
- 可靠: 字节的发送的顺序和收到的一致

Socket 则可以认为是 connection 的 endpoint，socket 地址是一个 `IPaddress:port` 对。

Port（端口）是一个 16 位的整数，用来标识不同的进程，利用不同的端口来连接不同的服务：

- Ephemeral port: Assigned automatically by client kernel when client makes a connection request

- Well-known port: Associated with some


  service

   

  provided by a server（在 linux 系统上可以在

   

  ```
  echo server: 7/echo
  ssh server: 22/ssh
  email server: 25/smtp
  web servers: 80/http
  ```

   

  中查看具体的信息）

  - echo server: 7/echo
  - ssh server: 22/ssh
  - email server: 25/smtp
  - web servers: 80/http



## http

HTTP请求
跟踪了新浪的首页，我们来总结一下HTTP请求的流程：

步骤1：浏览器首先向服务器发送HTTP请求，请求包括：
方法：GET还是POST，GET仅请求资源，POST会附带用户数据；
路径：/full/url/path；
域名：由Host头指定：Host: www.sina.com.cn以及其他相关的Header；
如果是POST，那么请求还包括一个Body，包含用户数据。

步骤2：服务器向浏览器返回HTTP响应，响应包括：
响应代码：200表示成功，3xx表示重定向，4xx表示客户端发送的请求有错误，5xx
表示服务器端处理时发生了错误；
响应类型：由Content-Type指定；
以及其他相关的Header；
通常服务器的HTTP响应会携带内容，也就是有一个Body，包含响应的内容，网页
的HTML源码就在Body中。

步骤3：如果浏览器还需要继续向服务器请求其他资源，比如图片，就再次发出
HTTP请求，重复步骤1、2。

Web采用的HTTP协议采用了非常简单的请求-响应模式，从而大大简化了开发。当
我们编写一个页面时，我们只需要在HTTP请求中把HTML发送出去，不需要考虑如
何附带图片、视频等，浏览器如果需要请求图片和视频，它会发送另一个HTTP请
求，因此，一个HTTP请求只处理一个资源。
HTTP协议同时具备极强的扩展性，虽然浏览器请求的是 http://www.sina.com.cn/ 的首页，但是新浪在HTML中可以链入其他服务器
的资源，比如 &lt;img src="http://i1.sinaimg.cn/home/2013/1008/U8455P30DT20131008135420.pn
g"&gt; ，从而将请求压力分散到各个服务器上，并且，一个站点可以链接到其他
站点，无数个站点互相链接起来，就形成了World Wide Web，简称WWW。



HTML文档就是一系列的Tag组成，最外层的Tag是 &lt;html&gt; 。规范的HTML
也包
含 &lt;head&gt;...&lt;/head&gt; 和 &lt;body&gt;...&lt;/body&gt; （注
意不要和HTTP的Header、Body搞混了），由于HTML是富文档模型，所以，还有
一系列的Tag用来表示链接、图片、表格、表单等等。

一个Web应用的本质就是：

1. 浏览器发送一个HTTP请求；
2. 服务器收到请求，生成一个HTML文档；
3. 服务器把HTML文档作为HTTP响应的Body发送给浏览器；
4. 浏览器收到HTTP响应，从HTTP Body取出HTML文档并显示。

# 并行与同步

进程和线程有什么差别？超线程又是什么意思？为什么多线程能够提高程序执行的速度？是所有情况都适用吗？

# JS

因为 toString 定义在 object 对象中，而所有对象最终都会在原型链上指
向 object ，所以 xiaoming 也拥有 toString 属性。

## map方法如下：

初始化 Map 需要一个二维数组，或者直接初始化一个空 Map 。 Map 具有以下方
法：

var m = new Map(); // 空Map
m.set('Adam', 67); // 添加新的key-value
m.set('Bob', 59);
m.has('Adam'); // 是否存在key 'Adam': true
m.get('Adam'); // 67
m.delete('Adam'); // 删除key 'Adam'
m.get('Adam'); // undefined

Set
Set 和 Map 类似，也是一组key的集合，但不存储value。由于key不能重复，所
以，在 Set 中，没有重复的key。
要创建一个 Set ，需要提供一个 Array 作为输入，或者直接创建一个空 Set ：
var s1 = new Set(); // 空Set
var s2 = new Set([1, 2, 3]);

有add()、delete()方法

## 迭代，其中有几种比较奇怪的for循环

编历列表能用for……in，但是对map和set之类的却没有办法，所以引入了新的编历——for …… of

for ... in 循环将把 name 包括在内（后天的属性都在循环之列），但 Array 的 length 属性却不包括在内。
for ... of 循环则完全修复了这些问题，它只循环集合本身的元素：

```
var a = ['A', 'B', 'C'];
var s = new Set(['A', 'B', 'C']);
var m = new Map([[1, 'x'], [2, 'y'], [3, 'z']]);
for (var x of a) { // 遍历Array
alert(x);
}
for (var x of s) { // 遍历Set
alert(x);
}
for (var x of m) { // 遍历Map
alert(x[0] + '=' + x[1]);
}
```

然而，更好的方式是直接使用 iterable 内置的 forEach 方法，它接收一个函
数，每次迭代就自动回调该函数。以 Array 为例：
var a = ['A', 'B', 'C'];
a.forEach(function (element, index, array) {
​	// element: 指向当前元素的值
​	// index: 指向当前索引
​	// array: 指向Array对象本身
​	alert(element);
​	});

## 函数

- 定义

  ```javascript
  在JavaScript中，定义函数的方式如下：
  function abs(x) {
  	if (x >= 0) {
  		return x;
  				}  
  	else {
  		return -x;
  		}
  }
  上述 abs() 函数的定义如下：
  function 指出这是一个函数定义；
  abs 是函数的名称；
  (x) 括号内列出函数的参数，多个参数以 , 分隔；
  { ... } 之间的代码是函数体，可以包含若干语句，甚至可以没有任何语句。
  ```

  ​


# Linux

- 账号管理

/root/.bash_history  记录输入的命令

使用 standard input 建立用户的密码
[root@study ~]# echo "密码" | passwd --stdin  用户名



~  帐户的 home 目录 可直接 cd ~chen（进入home中的chen目录）

- ACL 是 Access Control List 的缩写，主要的目的是在提供传统owner,group,others 的read,write,execute 权限之外的细部权限设定。ACL 可以针对单一使用者，单一文件或目录来进行r,w,x 的权限规范，对于需要特殊权限的使用状况非常有帮助。

```
 2. 针对特定群组的方式：
# 设定规范：『 g:[群组列表]:[rwx] 』，例如针对 mygroup1 的权限规范 rx ：
[root@study ~]# setfacl -m g:mygroup1:rx acl_test1
[root@study ~]# getfacl acl_test1

针对有效权限设定：『 m: 权限 』
基本上，群组与使用者的设定并没有什么太大的差异啦！如上表所示，非常容易了解意义。不过，你应该会觉得奇怪的是， 那个 mask 是什么东西啊？其实他有点像是『有效权限』的意思！他的意义是： 使用者或群组所设定的权限必须要存在于 mask 的权限设定范围内才会生效，此即『有效权限
(effective permission)』我们举个例子来看，如下所示：
# 3. 针对有效权限 mask 的设定方式：
# 设定规范：『 m:[rwx] 』，例如针对刚刚的文件规范为仅有 r ：
[root@study ~]# setfacl - - m m:r acl_test1
[root@study ~]# getfacl acl_test1
```

- su

su 就这样简单的介绍完毕，总结一下他的用法是这样的：
 若要完整的切换到新使用者的环境，必须要使用『 su - username 』或『 su -l username 』， 才会连同PATH/USER/MAIL 等变量都转成新用户的环境；

 如果仅想要执行一次 root 的指令，可以利用『 su - -c "指令串" 』的方式来处理；

 使用 root 切换成为任何使用者时，并不需要输入新用户的密码；
虽然使用 su 很方便啦，不过缺点是，当我的主机是多人共管的环境时，如果大家都要使用 su 来切换成为 root 的身份，那么不就每个人都得要知道 root 的密码，这样密码太多人知道可能会流出去，很不妥当呢！怎办？透过 sudo 来处理即可！



- sudo

由于 sudo 可以让你以其他用户的身份执行指令 (通常是使用 root 的身份来执行指令)，因此并非所有人都能够执行 sudo ， 而是仅有规范到/etc/sudoers 内的用户才能够执行 sudo 这个指令喔！

visudo 设置账号sudo权限

##script

- 计算小数、余数

那个 % 是取余数啦～
举例来说， 13 对 3 取余数，结果是 13=4*3+1，所以余数是 1 啊！就是：
[dmtsai@study bin]$ echo $(( 13 % 3 ))
1
这样了解了吧？另外，如果你想要计算含有小数点的数据时，其实可以透过 bc 这个指令的协助喔！ 例
如可以这样做：
[dmtsai@study bin]$ echo "123.123*55.9" | bc
6882.575

- 默认参数

![script默认参数](H:\Markdownbook\image\script默认参数.png)

使用shift可以从左减少对于的变量



- case……esac

一般来说，使用『 case $变量 in 』这个语法中，当中的那个『 $变量 』大致有两种取得的方式：
 直接下达式：例如上面提到的，利用『 script.sh variable 』 的方式来直接给予 $1 这个变量的内容，这也是在 /etc/init.d 目录下大多数程序的设计方式。
 交互式：透过 read 这个指令来让用户输入变量的内容。

```bash
case $变量名称 in <==关键词为 case ，还有变数前有钱字号
"第一个变量内容" ) <==每个变量内容建议用双引号括起来，关键词则为小括号 )
程序段
;; <==每个类别结尾使用两个连续的分号来处理！
"第二个变量内容" )
程序段
;;
* ) <==最后一个变量内容都会用 * 来代表所有其他值
不包含第一个变量内容与第二个变量内容的其他程序执行段
exit 1
;;
esac

例子
case ${1} in 
"hello")
	echo "Hello, how are you ?"
	;;
"")
	echo "You MUST input parameters, ex> {${0} someword}"
	;;
*) 
echo "Usage ${0} {hello}"
;;
esac
```




创建一个文件的cat：

```bash
cat > filename
[dmtsai@study ~]$ cat > catfile << "eof"
> This is a test.
> OK now stop
> eof <==输入这关键词，立刻就结束而不需要输入 [ctrl]+d
[dmtsai@study ~]$ cat catfile
This is a test.
OK now stop <
```





* 将数据同步写入硬盘中的指令： sync


* 惯用的关机指令： shutdown


* 重新启动，关机： reboot, halt, poweroff

在 Linux 当中，默认 root 的提示字符为 # ，而一般身份用户的提示字符为 $ 

其实我们都是透过『程序』在跟系统作沟通的，本章上面提到的窗口管理员或文本模式都是一组或一只程序在负责我们所想要完成的任务。 文本模式登入后所取得的程序被称为壳(Shell)，这是因为这支程序负责最外面跟使用者(我们)沟通，所以才被戏称为壳程序！

因为 bc 预设仅输出整数，如果要输出小数点下位数，那么就必须要执行 scale=number ，那个 number 就是小数点位数。

## 正则

- grep截取数据，egrep 在正规表示法里面是很常见的两支程序，其中， egrep 支持更严谨的正规表示法的语法；
- sed 本身也是一个管线命令，可以分析 standard input 的啦！ 而且 sed
  还可以将数据进行取代、删除、新增、撷取特定行等等的功能呢


- awk数据处理工具（字段）
- diff 主要是以『行』为单位比对， cmp 则是以『字节』为单位去比对，这并不相同

 . (小数点)：代表『一定有一个任意字符』的意思；
 * (星星号)：代表『重复前一个字符， 0 到无穷多次』的意思，为组合形态

* 代表的是『重复 0 个或多个前面的 RE 字符』的意义， 因此，『o*』代表的是：『拥有空字符或一个 o 以上的字符』， 特别注意，因为允许空字符(就是有没有字符都可以的意思)，因此，
  『 grep -n 'o*' regular_express.txt 』将会把所有的数据都打印出来屏幕上！
* 『.* 就代表零个或多个任意字符』的意思
* 因为 { 与 } 的符号在 shell 是有特殊意义的，因此， 我们必须要使用跳脱字符 \ 来让他失去特殊意义才行。 'o\ \{2\ }' ——两个o或者多个
* 举例来说，不支持正规表示法的 ls 这个工具中，若我们使用 『ls -l * 』 代表的是任意档名的文件，而 『ls -l a* 』代表的是以 a 为开头的任何档名的文件， 但在正规表示法中，我们要找到含有以 a为开头的文件，则必须要这样：(需搭配支持正规表示法的工具)
  ls | grep -n '^a.*'
* **去除空行也注释行  ，- v 参数 是选择不匹配的行**                                                   grep -v '^#' /etc/kdump.conf | grep -v '^$' 

RE 字符 意义与范例
^word
意义：待搜寻的字符串(word)在行首！
范例：搜寻行首为 # 开始的那一行，并列出行号
grep -n '^#' regular_express.txt

word$
意义：待搜寻的字符串(word)在行尾！
范例：将行尾为 ! 的那一行打印出来，并列出行号
grep -n '!$' regular_express.txt

.
意义：代表『一定有一个任意字符』的字符！
范例：搜寻的字符串可以是 (eve) (eae) (eee) (e e)， 但不能仅有 (ee) ！亦即 e 与 e
中间『一定』仅有一个字符，而空格符也是字符！
grep -n 'e.e' regular_express.txt

\
意义：跳脱字符，将特殊符号的特殊意义去除！
范例：搜寻含有单引号 ' 的那一行！
grep -n \' regular_express.txt

*
意义：重复零个到无穷多个的前一个 RE 字符
范例：找出含有 (es) (ess) (esss) 等等的字符串，注意，因为 * 可以是 0 个，所以 es 也是符合带搜寻字符串。另外，因为 * 为重复『前一个 RE 字符』的符号， 因此，在 * 之前必须要紧接着一个 RE 字符喔！例如任意字符则为 『.*』 ！
grep -n 'ess*' regular_express.txt

[list]
意义：字符集合的 RE 字符，里面列出想要撷取的字符！
范例：搜寻含有 (gl) 或 (gd) 的那一行，需要特别留意的是，在 [] 当中『谨代表一个待搜寻的字符』， 例如『 a[afl]y 』代表搜寻的字符串可以是 aay, afy, aly 即 [afl] 代表 a 或f 或 l 的意思！
grep -n 'g[ld]' regular_express.txt

[n1-n2]
意义：字符集合的 RE 字符，里面列出想要撷取的字符范围！
范例：搜寻含有任意数字的那一行！需特别留意，在字符集合 [] 中的减号 - 是有特殊意义的，他代表两个字符之间的所有连续字符！但这个连续与否与 ASCII 编码有关，因此，你的编码需要设定正确(在 bash 当中，需要确定 LANG 与 LANGUAGE 的变量是否正确！) 例如所有大写字符则为 [A-Z]
grep -n '[A-Z]' regular_express.txt

[^list]
意义：字符集合的 RE 字符，里面列出不要的字符串或范围！
范例：搜寻的字符串可以是 (oog) (ood) 但不能是 (oot) ，那个 ^ 在 [] 内时，代表的意义是『反向选择』的意思。 例如，我不要大写字符，则为 [^A-Z]。但是，需要特别注意的是，如果以 grep -n [ ^A-Z] regular_express.txt 来搜寻，却发现该文件内的所有行都被列出，为什么？因为这个 [ ^A-Z] 是『非大写字符』的意思， 因为每一行均有非大写字符，例如第一行的 "Open Source" 就有 p,e,n,o.... 等等的小写字
grep -n 'oo[ ^t]' regular_express.txt

\{n,m\}
意义：连续 n 到 m 个的『前一个 RE 字符』
意义：若为 \{n\} 则是连续 n 个的前一个 RE 字符，
意义：若是 \{n,\} 则是连续 n 个以上的前一个 RE 字符！ 范例：在 g 与 g 之间有 2 个到3 个的 o 存在的字符串，亦即 (goog)(gooog)
grep -n 'go\{2,3\}g' regular_express.txt

**+**意义：重复『一个或一个以上』的前一个 RE 字符范例：搜寻 (god) (good) (goood)... 等等的字符串。 那个 o+ 代表『一个以上的 o 』所以，底下的执行成果会将第 1, 9, 13 行列出来。egrep -n 'go+d' regular_express.txt

?
意义：『零个或一个』的前一个 RE 字符
范例：搜寻 (gd) (god) 这两个字符串。 那个 o? 代表『空的或 1 个 o 』所以，上面的执行成果会将第 13, 14 行列出来。 有没有发现到，这两个案例( 'go+d' 与 'go?d' )的结果集合与 'go*d' 相同？想想看，这是为什么喔！ ^_^
egrep -n 'go?d' regular_express.txt

|
意义：用或( or )的方式找出数个字符串
范例：搜寻 gd 或 good 这两个字符串，注意，是『或』！ 所以，第 1,9,14 这三行都可以被打印出来喔！
那如果还想要找出 dog 呢？
egrep -n 'gd|good' regular_express.txt
egrep -n 'gd|good|dog' regular_express.txt

()
意义：找出『群组』字符串
范例：搜寻 (glad) 或 (good) 这两个字符串，因为 g 与 d 是重复的，所以， 我就可以将 la 与 oo 列
于 ( ) 当中，并以 | 来分隔开来，就可以啦！
egrep -n 'g(la|oo)d' regular_express.txt

()+
意义：多个重复群组的判别
范例：将『AxyzxyzxyzxyzC』用 echo 叫出，然后再使用如下的方法搜寻一下！
echo 'AxyzxyzxyzxyzC' | egrep 'A(xyz)+C'
上面的例子意思是说，我要找开头是 A 结尾是 C ，中间有一个以上的 "xyz" 字符串的意思～

## bash

- 功能：补全、记录输入指令、脚本、通配符

  命令别名设定功能： (alias)
  假如我需要知道这个目录底下的所有文件 (包含隐藏档) 及所有的文件属性，那么我就必须要下达『 ls -al 』这样的指令串，唉！真麻烦，有没有更快的取代方式？呵呵！就使用命令别名呀！例如鸟哥最喜欢直接以 lm 这个自定义的命令来取代上面的命令，也就是说， lm 会等于 ls -al 这样的一个功能，嘿！那么要如何作呢？就使用 alias 即可！你可以在指令列输入 alias 就可以知道目前的命令别名有哪些了！也可以直接下达命令来设定别名呦：
   》alias lm='ls -al'

- **指令换行可以用  \ **

- **删除错误指令：**

  **[ctrl]+u/[ctrl]+k 分别是从光标处向前删除指令串 ([ctrl]+u) 及向后删除指令串 ([ctrl]+k)。**

  **[ctrl]+a/[ctrl]+e 分别是让光标移动到整个指令串的最前面 ([ctrl]+a) 或最后面 ([ctrl]+e)**

bash 默认的组合键给他
汇整如下：
组合按键 执行结果
Ctrl + C 终止目前的命令
Ctrl + D 输入结束 (EOF)，例如邮件结束的时候；
Ctrl + M 就是 Enter 啦！
Ctrl + S 暂停屏幕的输出
Ctrl + Q 恢复屏幕的输出
Ctrl + U 在提示字符下，将整列命令删除
Ctrl + Z 『暂停』目前的命令

**常用的通配符喔：**
**符号 意义**

*代表『 0 个到无穷多个』任意字符

? 代表『一定有一个』任意字符
[ ]同样代表『一定有一个在括号内』的字符(非任意字符)。例如 [abcd] 代表『一定有一个字符， 可能是 a, b,c, d 这四个任何一个』

[ - ]若有减号在中括号内时，代表『在编码顺序内的所有字符』。例如 [0-9] 代表 0 到 9 之间的所有数字，因为数字的语系编码是连续的！

[^ ]若中括号内的第一个字符为指数符号 (^) ，那表示『反向选择』，例如 [^abc] 代表 一定有一个字符，只要是非 a, b, c 的其他字符就接受的意思。

- 数据流导向（一个方向符是覆盖，两个是累加

1. 标准输入 (stdin) ：代码为 0 ，使用 < 或 << ；
2. 标准输出 (stdout)：代码为 1 ，使用 > 或 >> ；
3. 标准错误输出(stderr)：代码为 2 ，使用 2> 或 2>> ；

​                                2> /dev/null 丢到垃圾桶去

注意：

1. 该文件 (本例中是 ~/rootfile) 若不存在，系统会自动的将他建立起来，但是

2. 当这个文件存在的时候，那么系统就会先将这个文件内容清空，然后再将数据写入！
3. 也就是若以 > 输出到一个已存在的文件中，那个文件就会被覆盖掉啰！



 屏幕输出的信息很重要，而且我们需要将他存下来的时候；
 背景执行中的程序，不希望他干扰屏幕正常的输出结果时；
 一些系统的例行命令 (例如写在 /etc/crontab 中的文件) 的执行结果，希望他可以存下来时；
 一些执行命令的可能已知错误讯息时，想以『 2> /dev/null 』将他丢掉时；
 错误讯息与正确讯息需要分别输出时。

```bash
[dmtsai@study ~]$ ll / 				<==此时屏幕会显示出文件名信息
[dmtsai@study ~]$ ll / > ~/rootfile <==屏幕并无任何信息
[dmtsai@study ~]$ ll ~/rootfile 	<==有个新档被建立了！
-rw-rw-r--. 1 dmtsai dmtsai 1078 Jul 9 18:51 /home/dmtsai/rootfile

第一个命令的输出内容出现在了文件中


```



- 范例五：将指令的数据全部写入名为 list 的文件中

[dmtsai@study ~]$ find /home - name .bashrc > list 2> list <==错误
[dmtsai@study ~]$ find /home - name .bashrc > list 2>&1 <==正确
[dmtsai@study ~]$ find /home - name .bashrc &> list <==正确
上述表格第一行错误的原因是，由于两股数据同时写入一个文件，又没有使用特殊的语法， 此时两股数据可能会交叉写入该文件内，造成次序的错乱。所以虽然最终 list 文件还是会产生，但是里面的数据排列就会怪怪的，而不是原本屏幕上的输出排序。 至于写入同一个文件的特殊语法如上表所示，你可以使用 2>&1 也可以使用 &> ！ 一般来说，鸟哥比较习惯使用 2>&1 的语法啦！

解释：

File descriptor 1 is the standard output (stdout).

File descriptor 2 is the standard error (stderr).

Here is one way to remember this construct (although it is not entirely accurate): at first, `2>1` may look like a good way to redirect stderr to stdout. However, it will actually be interpreted as "redirect stderr to a file named `1`". **`&` indicates that what follows is a file descriptor and not a filenam**e. So the construct becomes: `2>&1`.

###指令下达情况 说明(连续指令如何作用)



​	**cmd1 && cmd2**

1. 若 cmd1 执行完毕且正确执行($?=0)，则开始执行 cmd2。

2. 若 cmd1 执行完毕且为错误 ($?≠0)，则 cmd2 不执行。

   **cmd1 || cmd2**

3. 若 cmd1 执行完毕且正确执行($?=0)，则 cmd2 不执行。

4. 若 cmd1 执行完毕且为错误 ($?≠0)，则开始执行 cmd2。

- 管道命令

在每个管线后面接的第一个数据必定是『指令』喔！而且这个指令必须要能够接受 standard input 的数据才行，这样的指令才可以是为『管线命令』，例less,more, head, tail 等都是可以接受 standard  input 的管线命令啦。至于例如 ls, cp, mv 等就不是管线命令了！因为 ls, cp, mv 并不会接受来自stdin 的数据。 也就是说，管线命令主要有两个比较需要注意的地方：
 管线命令仅会处理 standard output，对于 standard error output 会予以忽略
 管线命令必须要能够接受来自前一个指令的数据成为 standard input 继续处理才行。







![bash特殊字符1](H:\Markdownbook\image\bash特殊字符1.png)

![bash特殊字符2](H:\Markdownbook\image\bash特殊字符2.png)

### 变量

什么是『变量』呢？简单的说，就是让某一个特定字符串代表不固定的内容就是了。

那么由于在 Linux System 下面，所有的线程都是需要一个执行码， 而就如同上
面提到的，你『真正以 shell 来跟 Linux 沟通，是在正确的登入 Linux 之后！』这个时候你就有一个 bash 的执行程序，也才可以真正的经由 bash 来跟系统沟通啰！而在进入 shell 之前，也正如同上面提到的，由于系统需要一些变量来提供他数据的存取 (或者是一些环境的设定参数值， 例如是否要显示彩色等等的) ，所以就有一些所谓的『环境变量』 需要来读入系统中了！这些环境变量例如 PATH、HOME、MAIL、SHELL 等等，都是很重要的， 为了区别与自定义变量的不同，环境变量通常以大写字符来表示呢！

-  变数的取用: echo 例如： echo ${PATH}

**变量的设定规则**

1. 变量与变量内容以一个等号『=』来连结，如下所示：
  myname=VBird

2. 等号两边不能直接接空格符，如下所示为错误：
  myname = VBird或myname=VBird Tsai

3. 变量名称只能是英文字母与数字，但是开头字符不能是数字，如下为错误：
  2myname=VBird

4. 变量内容若有空格符可使用双引号『"』或单引号『'』将变量内容结合起来，如果有一个单引号，就需要用**“”**包括起来。
  o **双引号内的特殊字符如 $ 等，可以保有原本的特性**，如下所示：
  var="lang is *$LANG"*则echo  *$var*可得lang is zh_TW.UTF-8

  o **单引号内的特殊字符则仅为一般字符 (纯文本)**，如下所示：

  var='lang is \$LANG'则echo *$var*』可得『lang is $LANG』

  ​

5. 可用跳脱字符『 \ 』将特殊符号(如 [Enter], $, \, 空格符, '等)变成一般字符，如：
  『myname=VBird\ Tsai』

6. 在一串指令的执行中，还需要藉由其他额外的指令所提供的信息时，可以使用反单引号『\`指令\`』或 『$(指令)』。特别注意，那个 ` 是键盘上方的数字键 1 左边那个按键，而不是单引号！ 例如想要取得核心版本
  的设定：
  『version=\$(uname -r)』再『echo $version』可得『3.10.0-229.el7.x86_64』

7. 若该变量为扩增变量内容时，则可用 "$变量名称" 或 ${变量} 累加内容，如下所示：
  『PATH="$ PATH":/home/bin』或『PATH=  \${PATH}:/home/bin』

8. 若该变量需要在其他子程序执行，则需要以 export 来使变量变成环境变量：
  『export PATH』

9. 通常大写字符为系统默认变量，自行设定变量可以使用小写字符，方便判断 (纯粹依照使用者兴趣与嗜好) ；

10. 取消变量的方法为使用 unset ：『unset 变量名称』例如取消 myname 的设定：
  『unset myname』

11. 1.变量为null时


​    

   Shell代码  [![收藏代码](http://mappings.iteye.com/images/icon_star.png)](http://blog.csdn.net/joe_007/article/details/8773594)

      1. \#当变量a为null时则var=b  
      2. var=${a-b}  



   2.变量为null且为空字符串的时候

​    

​    

   Shell代码  ![收藏代码](http://mappings.iteye.com/images/icon_star.png] (http://blog.csdn.net/joe_007/article/details/8773594)

      1. \#当变量a为null或为空字符串时则var=b  
      2. var=${a:-b}  




### 变量键盘读取、数组与宣告： read, array, declare

- read

```bash
read [- - pt] variable
选项与参数：
-p ：后面可以接提示字符！
-t ：后面可以接等待的『秒数！』这个比较有趣～不会一直等待使用者啦！
范例一：让用户由键盘输入一内容，将该内容变成名为 atest 的变量
[dmtsai@study ~]$ read atest
This is a test <==此时光标会等待你输入！请输入左侧文字看看
[dmtsai@study ~]$ echo ${atest}
This is a test <==你刚刚输入的数据已经变成一个变量内容！


范例二：提示使用者 30 秒内输入自己的大名，将该输入字符串作为名为 named 的变量内容
[dmtsai@study ~]$ read - - p "Please keyin your name: " - - t 30 named
Please keyin your name: VBird Tsai <==注意看，会有提示字符喔！
[dmtsai@study ~]$ echo ${named}
VBird Tsai <==输入的数据又变成一个变量的内容了！
```



- declare

```bash
declare / typeset
declare 或 typeset 是一样的功能，就是在『宣告变量的类型』。如果使用 declare 后面并没有接任何参数，那么 bash 就会主动的将所有的变量名称与内容通通叫出来，就好像使用 set 一样啦！ 那么declare 还有什么语法呢？看看先：
[dmtsai@study ~]$ declare [- - aixr] variable
选项与参数：
-a ：将后面名为 variable 的变量定义成为数组 (array) 类型
-i ：将后面名为 variable 的变量定义成为整数数字 (integer) 类型
-x ：用法与 export 一样，就是将后面的 variable 变成环境变量；
-r ：将变量设定成为 readonly 类型，该变量不可被更改内容，也不能 unset

范例一：让变量 sum 进行 100+300+50 的加总结果
[dmtsai@study ~]$ sum=100+300+50
[dmtsai@study ~]$ echo ${sum}
100+300+50 <==咦！怎么没有帮我计算加总？因为这是文字型态的变量属性啊！
[dmtsai@study ~]$ declare - - i sum=100+300+50
[dmtsai@study ~]$ echo ${sum}
450 <==瞭乎？？

由于在默认的情况底下， bash 对于变量有几个基本的定义：
 变量类型默认为『字符串』，所以若不指定变量类型，则 1+2 为一个『字符串』而不是『计算式』。 所以上述第一个执行的结果才会出现那个情况的；
 bash 环境中的数值运算，预设最多仅能到达整数形态，所以 1/3 结果是 0；
现在你晓得为啥你需要进行变量宣告了吧？如果需要非字符串类型的变量，那就得要进行变量的宣告才行啦！ 底下继续来玩些其他的 declare 功能。

范例二：将 sum 变成环境变量
[dmtsai@study ~]$ declare - - x sum
[dmtsai@study ~]$ export | grep sum
declare -ix sum="450" <==果然出现了！包括有 i 与 x 的宣告！

范例三：让 sum 变成只读属性，不可更动！
[dmtsai@study ~]$ declare - - r sum
[dmtsai@study ~]$ sum=tesgting
-bash: sum: readonly variable <==老天爷～不能改这个变数了！

范例四：让 sum 变成非环境变量的自定义变量吧！
[dmtsai@study ~]$ declare +x sum <== 将 - 变成 + 可以进行『取消』动作
[dmtsai@study ~]$ declare - - p sum <== -p 可以单独列出变量的类型
declare -ir sum="450" <== 看吧！只剩下 i, r 的类型，不具有 x 啰！
```





- 数组

```bash
var关键字加上一个[参数]
范例：设定上面提到的 var[1] ～ var[3] 的变数。
[dmtsai@study ~]$ var[1]="s mall min"
[dmtsai@study ~]$ var[2]="big min"
[dmtsai@study ~]$ var[3]="nice min"
[dmtsai@study ~]$ echo "${var[1]}, ${var[2]}, ${var[3]}"
small min, big min, nice min
数组的变量类型比较有趣的地方在于『读取』，一般来说，建议直接以 ${数组} 的方式来读取，比
较正确无误的啦！这也是为啥鸟哥一开始就建议你使用 ${变量} 来记忆的原因！
```

### 与文件系统及程序的限制关系： ulimit

想象一个状况：我的 Linux 主机里面同时登入了十个人，这十个人不知怎么搞的， 同时开启了 100个文件，每个文件的大小约 10MBytes ，请问一下， 我的 Linux 主机的内存要有多大才够？10*100*10 = 10000 MBytes = 10GBytes ... 老天爷，这样，系统不挂点才有鬼哩！为了要预防这个情况的发生，所以我们的 bash 是可以『限制用户的某些系统资源』的，包括可以开启的文件数量， 可以使用的 CPU 时间，可以使用的内存总量等等。如何设定？用 ulimit 吧！

```bash
[dmtsai@study ~]$ ulimit [- - SHacdfltu] [ 配 额] ]
选项与参数：
-H ：hard limit ，严格的设定，必定不能超过这个设定的数值；
-S ：soft limit ，警告的设定，可以超过这个设定值，但是若超过则有警告讯息。在设定上，通常 soft 会比 hard 小，举例来说，soft 可设定为 80 而 hard设定为 100，那么你可以使用到 90 (因为没有超过 100)，但介于 80~100 之间时，系统会有警告讯息通知你！

-a ：后面不接任何选项与参数，可列出所有的限制额度；
-c ：当某些程序发生错误时，系统可能会将该程序在内存中的信息写成文件(除错用)，
这种文件就被称为核心文件(core file)。此为限制每个核心文件的最大容量。
-f ：此 shell 可以建立的最大文件容量(一般可能设定为 2GB)单位为 Kbytes
-d ：程序可使用的最大断裂内存(segment)容量；
-l ：可用于锁定 (lock) 的内存量
-t ：可使用的最大 CPU 时间 (单位为秒)
-u ：单一用户可以使用的最大程序(process)数量。

范例一：列出你目前身份(假设为一般账号)的所有限制数据数值
[dmtsai@study ~]$ ulimit -a 
core file size (blocks, -c) 0 <==只要是 0 就代表没限制
data seg size (kbytes, -d) unlimited
scheduling priority (-e) 0
file size (blocks, -f) unlimited <==可建立的单一文件的大小
pending signals (-i) 4903
max locked memory (kbytes, -l) 64
max memory size (kbytes, -m) unlimited
open files (-n) 1024 <==同时可开启的文件数量
pipe size (512 bytes, -p) 8
POSIX message queues (bytes, -q) 819200
real-time priority (-r) 0
stack size (kbytes, -s) 8192
cpu time (seconds, -t) unlimited
max user processes (-u) 4096
virtual memory (kbytes, -v) unlimited
file locks (-x) unlimited
范例二：限制用户仅能建立 10MBytes 以下的容量的文件
[dmtsai@study ~]$ ulimit - - f 10240
[dmtsai@study ~]$ ulimit - - a | grep 'file size'
core file size (blocks, -c) 0
file size (blocks, -f) 10240 <==最大量为 10240Kbyes，相当 10Mbytes
[dmtsai@study ~]$ dd if=/dev/zero of=123 bs=1M count=20
File size limit exceeded (core dumped) <==尝试建立 20MB 的文件，结果失败了！
[dmtsai@study ~]$ rm 123 <==赶快将这个文件删除啰！同时你得要注销再次的登入才能解开 10M 的限制
```

### 删除、修改变量P445

${变量#关键词}     若变量内容从头开始的数据符合『关键词』，则将符合的最短数据删除

${变量##关键词}   若变量内容从头开始的数据符合『关键词』，则将符合的最长数据删除


${变量%关键词}    若变量内容从尾向前的数据符合『关键词』，则将符合的最短数据删除
${变量%%关键词}   若变量内容从尾向前的数据符合『关键词』，则将符合的最长数据删除


${变量/旧字符串/新字符串}    若变量内容符合『旧字符串』则『第一个旧字符串会被新字符串取代』
${变量//旧字符串/新字符串}  若变量内容符合『旧字符串』则『全部的旧字符串会被新字符串取代』





范例一：先让小写的 path 自定义变量设定的与 PATH 内容相同
[dmtsai@study ~]$ path=${PATH}
[dmtsai@study ~]$ echo ${path}
/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/dmtsai/.local/bin:/home/dmtsai/bin
范例二：假设我不喜欢 local/bin，所以要将前 1 个目录删除掉，如何显示？
[dmtsai@study ~]$ echo ${path#/*local/bin:}
/usr/bin:/**usr/local/sbin:**/usr/sbin:/home/dmtsai/.local/bin:/home/dmtsai/bin

解析：，path代表变量名，**#代表由前面开始**删除，所以这里便由开始的 / 写起。需要注意的是，我们还可以透过通配符 * 来取代 0 到无穷多个任意字，删除的是黑体字部分。因为 一个#代表找最短的删除，两个##反而是最长的。看不懂这种环境变量的分隔。

%代表由后面开始删除。

### 变量的测试与内容替换

```bash
在某些时刻我们常常需要『判断』某个变量是否存在，若变量存在则使用既有的设定，若变量不存在
则给予一个常用的设定。 我们举底下的例子来说明好了，看看能不能较容易被你所理解呢！
范例一：测试一下是否存在 username 这个变量，若不存在则给予 username 内容为 root
[dmtsai@study ~]$ echo ${username}
<==由于出现空白，所以 username 可能不存在，也可能是空字符串
[dmtsai@study ~]$ username=${username-root}
[dmtsai@study ~]$ echo ${username}
root <==因为 username 没有设定，所以主动给予名为 root 的内容。
[dmtsai@study ~]$ username="vbird tsai" <==主动设定 username 的内容
[dmtsai@study ~]$ username=${username-root}
[dmtsai@study ~]$ echo ${username}
vbird tsai <==因为 username 已经设定了，所以使用旧有的设定而不以 root 取代
```

**当有-的时候就是设定变量给定值，但是一旦确定了变量的值就只用设定的**

另外加上：是直接替换

```bash
范例二：若 username 未设定或为空字符串，则将 username 内容设定为 root
[dmtsai@study ~]$ username=""
[dmtsai@study ~]$ username=${username-root}
[dmtsai@study ~]$ echo ${username}
<==因为 username 被设定为空字符串了！所以当然还是保留为空字符串！
[dmtsai@study ~]$ username=${username:-root}
[dmtsai@study ~]$ echo ${username}
root <==加上『 : 』后若变量内容为空或者是未设定，都能够以后面的内容替换！
```

- 总结

![bash替换](H:\Markdownbook\image\bash替换.png)

![bash替换2](H:\Markdownbook\image\bash替换2.png)

### 历史命令技巧

[dmtsai@study ~]$ !number
[dmtsai@study ~]$ !command
[dmtsai@study ~]$ !!
选项与参数：
number ：执行第几笔指令的意思；
command ：由最近的指令向前搜寻『指令串开头为 command』的那个指令，并执行；
!! ：就是执行上一个指令(相当于按↑按键后，按 Enter)

#### 指令的执行

基本上，指令运作的顺序可以这样看：

1. 以相对/绝对路径执行指令，例如『 /bin/ls 』或『 ./ls 』；
2. 由 alias 找到该指令来执行；
3. 由 bash 内建的 (builtin) 指令来执行；
4. 透过 $PATH 这个变量的顺序搜寻到的第一个指令来执行。

由type -a command 可以指导顺序：

```
[chen@localhost ~]$ type -a ls
ls 是 `ls --color=auto' 的别名
ls 是 /usr/bin/ls
ls 是 /bin/ls

```





## vi、nano 之类的编辑器

* nano

 [ctrl]-G：取得联机帮助(help)，很有用的！
 [ctrl]-X：离开 naon 软件，若有修改过文件会提示是否需要储存喔！
 [ctrl]-O：储存文件，若你有权限的话就能够储存文件了；
[ctrl]-R：从其他文件读入资料，可以将某个文件的内容贴在本文件中；
[ctrl]-W：搜寻字符串，这个也是很有帮助的指令喔！
[ctrl]-C：说明目前光标所在处的行数与列数等信息；
[ctrl]-_：可以直接输入行号，让光标快速移动到该行；
[alt]-Y：校正语法功能开启或关闭(单击开、再单击关)
[alt]-M：可以支持鼠标来移动光标的功能

- vi

### **第一部份：一般指令模式可用的按钮说明，光标移动、复制贴上、搜寻取代等**

移动光标的方法(可以加上数字移动到相应的列或行)
h 或 向左箭头键(←) 光标向左移动一个字符
j 或 向下箭头键(↓) 光标向下移动一个字符
k 或 向上箭头键(↑) 光标向上移动一个字符
l 或 向右箭头键(→) 光标向右移动一个字符
如果你将右手放在键盘上的话，你会发现 hjkl 是排列在一起的，因此可以使用这四个按钮来移动光标。 如果想要进行多次移动的话，例如向下移动 30 列，可以使用 "30j" 或 "30↓" 的组合按键， 亦即加上想要进行的次数(数字)后，按下动作即可！
[Ctrl] + [f] 屏幕『向下』移动一页，相当于 [Page Down]按键 (常用)
[Ctrl] + [b] 屏幕『向上』移动一页，相当于 [Page Up] 按键 (常用)
[Ctrl] + [d] 屏幕『向下』移动半页
[Ctrl] + [u] 屏幕『向上』移动半页

*+* 光标移动到非空格符的下一列

*-* 光标移动到非空格符的上一列

n<space> 那个 n 表示『数字』，例如 20 。按下数字后再按空格键，光标会向右移动这一列的 n个字符。例如 20<space> 则光标会向后面移动 20 个字符距离。

0 或功能键[Home] 这是数字『 0 』：移动到这一列的最前面字符处 (常用)

$ 或功能键[End] 	移动到这一列的最后面字符处(常用)
H 光标移动到这个屏幕的最上方那一列的第一个字符
M 光标移动到这个屏幕的中央那一列的第一个字符
L 光标移动到这个屏幕的最下方那一列的第一个字符
G 移动到这个文件的最后一列(常用)

nG  n 为数字。移动到这**个文件的第 n 列**。例如 20G 则会移动到这个文件的第 20 列(可配合 :set nu)

gg 移动到这个文件的第一列，相当于 1G 啊！ (常用)

n<Enter>   n 为数字。光标向下移动 n 列(常用)



### **搜寻与取代**

/word  向光标之下寻找一个名称为 word 的字符串。例如要在文件内搜寻 vbird 这个字符串，就输入 /vbird 即可！ (常用)

**?word   向光标之上寻找一个字符串名称为 word 的字符串。**

n 这个 n 是英文按键。代表『重复前一个搜寻的动作』。举例来说， 如果刚刚我们执行/vbird 去向下搜寻 vbird 这个字符串，则按下 n 后，会向下继续搜寻下一个名称为vbird 的字符串。如果是执行 ?vbird 的话，那么按下 n 则会向上继续搜寻名称为vbird 的字符串！

N这个 N 是英文按键。与 n 刚好相反，为『反向』进行前一个搜寻动作。 例如 /vbird后，按下 N 则表示『向上』搜寻 vbird 。使用 /word 配合 n 及 N 是非常有帮助的！可以让你重复的找到一些你搜寻的关键词！

:n1,n2s/word1/word2/g      n1 与 n2 为数字。在第 n1 与 n2 列之间寻找 word1 这个字符串，并将该字符串**取代**为 word2 ！举例来说，在 100 到 200 列之间搜寻 vbird 并取代为 VBIRD 则：『:100,200s/vbird/VBIRD/g』。(常用)

:1,$s/word1/word2/g 从第一列到最后一列寻找 word1 字符串，并将该字符串取代为 word2 ！(常用)

:1,$s/word1/word2/gc 从第一列到最后一列寻找 word1 字符串，并将该字符串取代为 word2 ！且在取代前显示提示字符给用户确认 (confirm) 是否需要取代！(常用)

### **删除、复制与贴上**

x, X 在一列字当中，x 为向后删除一个字符 (相当于 [del] 按键)， X 为向前删除一个字符(相当于 [backspace] 亦即是退格键) (常用)

nx    n 为数字，连续向后删除 n 个字符。举例来说，我要连续删除 10 个字符， 『10x』。

dd 删除游标所在的那一整列(常用)

ndd n 为数字。删除光标所在的向下 n 列，例如 20dd 则是删除 20 列 (常用)

d1G 删除光标所在到第一列的所有数据

dG 删除光标所在到最后一列的所有数据

d$ 删除游标所在处，到该列的最后一个字符

d0 那个是数字的 0 ，删除游标所在处，到该列的最前面一个字符

yy 复制游标所在的那一列(常用)

nyy   n 为数字。复制光标所在的向下 n 列，例如 20yy 则是复制 20 列(常用)

y1G 复制光标所在列到第一列的所有数据

yG 复制光标所在列到最后一列的所有数据

y0 复制光标所在的那个字符到该列行首的所有数据

y$ 复制光标所在的那个字符到该列行尾的所有数据



p, P   p 为将已复制的数据在光标下一列贴上，P 则为贴在游标上一列！ 举例来说，我目前光标在第 20 列，且已经复制了 10 列数据。则按下 p 后， 那 10 列数据会贴在原本的 20 列之后，亦即由 21 列开始贴。但如果是按下 P 呢？ 那么原本的第 20 列会被推到变成 30 列。 (常用)

J 将光标所在列与下一列的数据结合成同一列

c 重复删除多个数据，例如向下删除 10 列，[ 10cj ]

u 复原前一个动作。(常用)

[Ctrl]+r 重做上一个动作。(常用) 这个 u 与 [Ctrl]+r 是很常用的指令！一个是复原，另一个则是重做一次～ 利用这两个功能按键，你的编辑，嘿嘿！很快乐的啦！

. 不要怀疑！这就是小数点！意思是重复前一个动作的意思。 如果你想要重复删除、重复贴上等等动作，按下小数点『.』就好了！ (常用)



###  **第二部份：一般指令模式切换到编辑模式的可用的按钮说明进入插入或取代的编辑模式**

i, I
进入插入模式(Insert mode)：i 为『从目前光标所在处插入』， I 为『在目前所在列的第一个非空格符处开始插入』。(常用)

a, A
进入插入模式(Insert mode)：a 为『从目前光标所在的下一个字符处开始插入』， A 为『从光标所在列的最后一个字符处开始插入』。(常用)

o, O
进入插入模式(Insert mode)：这是英文字母 o 的大小写。o 为『在目前光标所在的下一列处插入新的一列』； O 为在目前光标所在处的上一列插入新的一列！(常用)

r, R
进入取代模式(Replace mode)：r 只会取代光标所在的那一个字符一次；R 会一直取代光标所在的文字，直到按下 ESC为止；(常用)

上面这些按键中，在 vi 画面的左下角处会出现『--INSERT--』或『--REPLACE--』的字样。 由名称就知道该动作了吧！！特别注意的是，我们上面也提过了，你想要在文件里面输入字符时， 一定要在左下角处看到 INSERT 或 REPLACE才能输入喔！

[Esc] 退出编辑模式，回到一般指令模式中(常用)

### **第三部份：一般指令模式切换到指令列模式的可用按钮说明**

**指令列模式的储存、离开等指令**

:w 将编辑的数据写入硬盘文件中(常用)

:w! 若文件属性为『只读』时，强制写入该文件。不过，到底能不能写入， 还是跟你对该文件的文件权限有关啊！

:q 离开 vi (常用)

:q! 若曾修改过文件，又不想储存，使用 ! 为强制离开不储存文件。注意一下啊，那个惊叹号 (!) 在 vi 当中，常常具有『强制』的意思～

:wq 储存后离开，若为 :wq! 则为强制储存后离开 (常用)

ZZ 这是大写的 Z 喔！若文件没有更动，则不储存离开，若文件已经被更动过，则储存后离开！

:w [filename] 将编辑的数据储存成另一个文件（类似另存新档）

:r [filename]在编辑的数据中，读入另一个文件的数据。亦即将 『filename』 这个文件内容加到游标所在列后面

:n1,n2 w [filename] 将 n1 到 n2 的内容储存成 filename 这个文件。

:! command 暂时离开 vi 到指令列模式下执行 command 的显示结果！例如『:! ls /home』即可在 vi 当中察看 /home 底下以 ls 输出的文件信息！

**vim 环境的变更**

:set nu 显示行号，设定之后，会在每一列的前缀显示该列的行号
:set nonu 与 set nu 相反，为取消行号！

### 块处理P404

v 字符选择，会将光标经过的地方反白选择！
V 列选择，会将光标经过的列反白选择！
[Ctrl]+v 区块选择，可以用长方形的方式选择资料
y 将反白的地方复制起来
d 将反白的地方删除掉
p 将刚刚复制的区块，在游标所在处贴上！



## **多窗口情况下的按键功能**



:sp [filename]开启一个新窗口，如果有加 filename， 表示在新窗口开启一个新文件，否则表示两个窗口为同一个文件内容(同步显示)。

n[ctrl]+w+ j
[ctrl]+w+↓
按键的按法是：先按下 [ctrl] 不放， 再按下 w 后放开所有的按键，然后再按下 j (或向下箭头键)，则光标可移动到下方的窗口。

[ctrl]+w+ k
[ctrl]+w+↑
同上，不过光标移动到上面的窗口。

[ctrl]+w+ q
其实就是 :q 结束离开啦！ 举例来说，如果我想要结束下方的窗口，那么利用[ctrl]+w+



- **多文件**

多文件编辑的按键
:n 编辑下一个文件
:N 编辑上一个文件
:files 列出目前这个 vim 的开启的所有文件

1. 透过『 vim hosts /etc/hosts 』指令来使用一个 vim 开启两个文件；

2. 在 vim 中先使用『 :files 』察看一下编辑的文件数据有啥？结果如下所示。 至于下图的最后一列显示的
  是『按下任意键』就会回到 vim 的一般指令模式中！
  ​
3. 在第一列输入『 4yy 』复制四列；
4. 在 vim 的环境下输入『 :n 』会来到第二个编辑的文件，亦即 /etc/hosts 内；
5. 在 /etc/hosts 下按『 G 』到最后一列，再输入『 p 』贴上；
6. 按下多次的『 u 』来还原原本的文件数据；
7. 最终按下『 :q 』来离开 vim 的多文件编辑吧！

### 补全

鸟哥建议可以记忆的主要 vim 补齐功能，大致有底下几个：
组合按钮 补齐的内容
[ctrl]+x -> [ctrl]+n 透过目前正在编辑的这个『文件的内容文字』作为关键词，予以补齐

[ctrl]+x -> [ctrl]+f  以当前目录内的『文件名』作为关键词，予以补齐

[ctrl]+x -> [ctrl]+o 以扩展名作为语法补充，以 vim 内建的关键词，予以补齐

##命令

不过，鸟哥主要还是以理解『在什么情况下，应该要使用哪方面的指令』为准的！既然鸟哥说不需要背指令，那么我们如何知道每个指令的详细用法？还有，某些配置文件的内容到底是什么？ 这个可就不需要担心了！因为在 Linux 上开发的软件大多数都是自由软件/开源软件，而这些软件的开发者为了让大家能够了解指令的用法， 都会自行制作很多的文件，而这些文件也可以直接在在线就能够轻易的被使用者查询出来喔！很不赖吧！ 这根本就是**『联机帮助文件』**嘛！

```
man [help]
```

通常鸟哥在查询某个数据时是这样来查阅的：

1. 先察看 NAME 的项目，约略看一下这个资料的意思；
2. 再详看一下 DESCRIPTION，这个部分会提到很多相关的资料与使用时机，从这个地方可以学到很多小细节呢；
3. 而如果这个指令其实很熟悉了(例如上面的 date)，那么鸟哥主要就是查询关于 OPTIONS 的部分了！ 可以知道每个选项的意义，这样就可以下达比较细部的指令内容呢！
4. 最后，鸟哥会再看一下，跟这个资料有关的还有哪些东西可以使用的？举例来说，上面的 SEE ALSO 就告知我们还可以利用『info coreutils date』来进一步查阅数据；
5. 某些说明内容还会列举有关的文件(FILES 部分)来提供我们参考！这些都是很有帮助的！

```
man page 常用的按键给他整理整理：
按键 进行工作
空格键 向下翻一页
[Page Down] 向下翻一页
[Page Up] 向上翻一页
[Home] 去到第一页
[End] 去到最后一页
/string 向『下』搜寻 string 这个字符串，如果要搜寻 vbird 的话，就输入 /vbird
?string 向『上』搜寻 string 这个字符串

n, N利用 / 或 ? 来搜寻字符串时，可以用 n 来继续下一个搜寻 (不论是 / 或 ?) ，可以利用 N 来进行『反向』搜寻。举例来说，我以 /vbird 搜寻 vbird 字符串， 那么可以 n 继续往下询，用 N 往上查询。若以 ?vbird 向上查询 vbird 字符串， 那我可以用 n 继续『向上』查询，用 N 反向查询。

q 结束这次的 man page
```



**『man -f 指令』时，man 只会找数据中的左边那个指令(或文件)的完整名称**，有一点不同都不行！ 但如果我想要找的是『关键词』呢？也就是说，我想要同时找上面说的两个地方的内容，只要该内容有关键词存在， 不需要完全相同的指令(或文件)就能够找到时，

**man -k man 查询包含man这几个字母的命令**

```
dmtsai@study ~]$ whatis [ 指令或者是 数 据] ] <==相当于 man -f [指令或者是数据]
[dmtsai@study ~]$ apropos [ 指令或者是 数 据] ] <==相当于 man -k [指令或者是数据]
```

在终端机模式中，如果你知道某个指令，但却忘记了相关选项与参数，请先善用 --help 的功能来查询相关信息；

1.  当有任何你不知道的指令或文件格式这种玩意儿，但是你想要了解他，请赶快使用 man 或者是 info 来查询！
2.  而如果你想要架设一些其他的服务，或想要利用一整组软件来达成某项功能时，请赶快到/usr/share/doc 底下查一查有没有该服务的说明档喔！



三个指令可以进行重新启动与关机的任务，那就是 **reboot, halt, poweroff**。 其实这三个指令呼叫的函式库都差不多，所以当你使用『man reboot』时，会同时出现三个指令的用法给你看呢。 其实鸟哥通常都只有记 poweroff 与 reboot 这两个指令啦！一般鸟哥在重新启动时，都会下达如下的指令喔：
[root@study ~]# sync; sync; sync; reboot

[Tab] 接在一串指令的第一个字的后面，则为『命令补全』；
[Tab] 接在一串指令的第二个字以后时，则为『文件补齐』！

**[Ctrl]-d 按键**
那么[Ctrl]-d 是什么呢？就是[Ctrl]与 d 按键的组合啊！这个组合按键通常代表着： 『**键盘输入结束(End Of File, EOF 或 End Of Input)』的意思！** 另外，他也可以用来取代 exit 的输入呢！例如你

想要直接离开文字接口，可以直接按下[Ctrl]-d 就能够直接离开了(相当于输入 exit 啊！)。

**[shift]+{[PageUP]|[Page Down]}** 按键如果你在纯文本的画面中执行某些指令，这个指令的输出讯息相当长啊！所以导致前面的部份已经不在目前的屏幕画面中， 所以你想要回头去瞧一瞧输出的讯息，那怎办？其实，**你可以使用[Shift]+[Page Up] 来往前翻页，也能够使用 [Shift]+[Page Down] 来往后翻页！** 

Linux就是核心和系统调用接口两层。它提供了完整的操作系统当中的底层的硬件控制与资源管理的完整架构。

* top 查看进程

* ls -i 查看目录项

* stat [file] 查看某文件的Inode信息

* ls il 查看目录的Inode信息

* ls ial 查看隐藏文件

* ls -s 参看文件或目录

* cd ~ 进入当前主目录

* ps a命令可以看到mingetty软件虚拟了六个命令行终端

* tty命令查看目前是哪一个终端

* startx命令启动图形接口程序（Xwindow），前提是X window这个程序你已经安装了。

* ps a命令查看目前的终端使用情况

* 使用pstree命令可以看到gnome-terminal软件创建了2个模拟终端（树型结构）

* ls -l命令，可以了解文件的访问权

* ls –ld命令，可以了解目录的访问权限

  ​



* ​



![常见目录](H:\Markdownbook\image\常见目录.png)



![var目录](H:\Markdownbook\image\var目录.png)



命令接口：它是一组键盘操作命令组成。用户通过控制台或终端打入操作命令，向系统提出种种要求。用户每当打完一条命令，控制就转入解释系统，该系统立即对该命令解释执行，完成指定功能；然后，又转回控制台或终端，此时，用户又可打入下一条命令。如此反复，直到一个作业完成为止。

![程序接口](H:\Markdownbook\image\程序接口.png)





第一，为了达到接受用户的输入操纵计算机的目的，需要有一个终端处理程序接受用户输入，然后需要一个命令解释程序对命令进行判断；可见，命令解释程序的主要作用，是在屏幕上给出提示符，请用户键入命令，然后读入该命令，识别命令，再转到相应命令处理程序的入口地址，把控制权交给该处理程序去执行，并将处理结果送屏幕上显示。

普通用户可以简单的把终端和控制台理解为：可以输入命令行并显示程序运行过程中的信息以及程序运行结果的窗口。



![命令接口分析](H:\Markdownbook\image\命令接口分析.png)



模拟终端也是一种字符型设备，通常使用pts/0,1,2等来简称终端设备。在Linux系统的设备文件目录/dev/下，模拟终端对应的设备文件为pts/0~pts/n。



为了能向用户提供多方面的服务，通常，OS都向用户提供了几十条甚至上百条的联机命令。根据这些命令所完成功能的不同，可把它们分成以下几类：①
系统管理命令；② 文件和目录类命令； ③ 系统信息类命令；④ 进程管理类命令；⑤ 软件安装类命令； ⑥ 压缩解压命令；⑦其它命令![编程接口的解释](H:\Markdownbook\image\编程接口的解释.png)



![用户态](H:\Markdownbook\image\用户态.png)

用户态和系统态之间通过中断程序（函数）进行转换，状态的转换通过软中断实现在运行系统调用时，由于调用和被调用过程是工作在不同的系统状态，因而不允许由调用过程直接转向被调用过程。通常都是通过软中断机制（int0x80），先由用户态转换为系统态，经核心分析后，才能转向相应的系统调用服务例程。

![用户态和系统态的转换](H:\Markdownbook\image\用户态和系统态的转换.png)



系统调用是操作系统的最小功能单位，是一种不能再化简的操作（类似于原子操作）。有时候为了实现比较复杂的功能，就必须调用很多的系统调用。这势必会加重程序员的负担。

**linux启动过程**

![引导启动过程](H:\Markdownbook\image\引导启动过程.png)

* BIOS 

  1. 硬件自检

  2. 启动顺序（下一阶段的引导程序）BIOS需要有一个外部储存设备的排序，排在前面的设备就是优先转交控制权的设备。这种排序叫做"启动顺序"（Boot Sequence）

  3. 加载引导扇区（MBR），计算机读取该设备的第一个扇区（引导扇区），也就是读取最前面的512个字节。如果这512个字节的最后两个字节是0x55和0xAA，表明这个设备可以用于启动；如果不是，表明设备不能用于启动，控制权于是被转交给"启动顺序"中的下一个设备。 这512字节叫做“主引导记录”，MBR由三部分构成：

       1． boot loader ，占446字节;boot loader就是引导加载器，任务是加载Linux内核。在linux系统中，常用的boot loader是grub}

     　　2．硬盘分区表DPT，占64字节

     　　3．主引导记录结束标志AA55H

     ​

     实际上这里BIOS并不关心启动设备第一个扇区中是什么内容，它只是负责读取该扇区内容、并执行。 至此，BIOS的任务就完成了，此后将系统启动的控制权移交到MBR部分的代码。

  * 第二阶段 grub

    1. grub stage1,就是MBR中的主引导程序代码（446个，基本上，stage1只负责做引导的动作，也就是为后面的步骤做铺垫的工作。它的唯一作用就是加载stage1.5，将磁盘第二个扇区的内容加载到内存，然后将控制权交给stage1.5。

    2. grub stage1.5，stage1.5一般紧跟在MBR后面,
       MBR后面的n个扇区中都是stage1.5，从第二个扇区到第N个扇区。

       第二个扇区的作用就是加载磁盘的第三个扇区到第N个扇区到内存，N取几，取决与文件系统驱动代码的大小

       grub 执行安装的时候，能够识别启动设备的文件系统，比如我们是ext4文件系统，所以安装系统时只需要将ext4部分的e2fs_stage1_5放入这N个扇区就可以了。

    3. grub stage2，在stage1.5加载文件系统驱动后，将/boot/grub/stage2文件载入内存，并将控制权交给它。

    Stage2文件主要提供的功能如下：
    1、读取配置文件/boot/grub/grub.conf

    2、在屏幕上显示操作系统的启动选择界面

    在交互界面中可以为要启动的内核传递参数

    3、将用户选择的（或配置文件中默认的）内核加载到内存，并将控制权移交给此内核

  * 第三阶段 内核启动

    linux有这7个启动级别分别为：  

      0      –    系统停机

      1      –   单用户模式

      2      –   不支持NFS的多用户模式

      3      –   支持NFS的多用户模式

      4      –    未使用

      5      –   X11图形模式（X-Window）

      6      –   系统重启


## 翻页简视

前面提到的 nl 与 cat, tac 等等，都是一次性的将数据一口气显示到屏幕上面，那有没有可以进行一页一页翻动的指令啊？ 让我们可以一页一页的观察，才不会前面的数据看不到啊～呵呵！有的！那就是 more 与 less 啰～

more  文件

- 空格键 (space)：代表向下翻一页；

* Enter ：代表向下翻『一行』；
* /字符串 ：代表在这个显示的内容当中，向下搜寻『字符串』这个关键词；
* :f ：立刻显示出文件名以及目前显示的行数；
* q ：代表立刻离开 more ，不再显示该文件内容。
* b 或 [ctrl]-b ：代表往回翻页，不过这动作只对文件有用，对管线无用。

less 的用法比起 more 又更加的有弹性，怎么说呢？在 more 的时候，我们并没有办法向前面翻， 只能往后面看，但若使用了 less 时，呵呵！就可以使用 [pageup][pagedown] 等按键的功能来往前往后
翻看文件，你瞧，是不是更容易使用来观看一个文件的内容了呢！
除此之外，在 less 里头可以拥有更多的『搜寻』功能喔！不止可以向下搜寻，也可以向上搜寻～ 实在是很不错用～基本上，可以输入的指令有：
 空格键 ：向下翻动一页；
 [pagedown]：向下翻动一页；
 [pageup] ：向上翻动一页；
 /字符串 ：向下搜寻『字符串』的功能；
 ?字符串 ：向上搜寻『字符串』的功能；
 n ：重复前一个搜寻 (与 / 或 ? 有关！)
 N ：反向的重复前一个搜寻 (与 / 或 ? 有关！)
 g ：前进到这个资料的第一行去；
 G ：前进到这个数据的最后一行去 (注意大小写)；
 q ：离开 less 这个程序；

## 使用者、目录

cd - 是切换上一层目录

mkdir p 可以建立没有上层目录的目录

mkdir -m 创建的目录改变默认属性

假如我想要显示 /etc/man_db.conf 的第 11 到第 20 行呢？
答：这个应该不算难，想一想，在第 11 到第 20 行，那么我取前 20 行，再取后十行，所以结果就是：『 head -n 20 /etc/man_db.conf | tail -n 10 』，这样就可以得到第 11 到第 20 行之间的内容了！
​        这两个指令中间有个**管线 (|) 的符号存在，这个管线的意思是：『前面的指令所输出的讯息，请透过管线交由后续的指令继续使用』的意思。** 所以， head -n 20 /etc/man_db.conf 会将文件内的 20 行取出来，但不输出到屏幕上，而是转交给后续的 tail 指令继续处理。 因此 tail 『不需要接档名』，因为 tail 所需要的数据是来自于 head 处理后的结果！这样说，有没有理解？

- 文件具有 SUID 的特殊权限时，代表当用户执行此一 binary 程序时，在执行过程中用户会暂时具有程序拥有者的权限


- 目录具有 SGID 的特殊权限时，代表用户在这个目录底下新建的文件之群组都会与该目录的组名相同。


- 目录具有 SBIT 的特殊权限时，代表在该目录下用户建立的文件只有自己与 root 能够删除！

- rwx（1）rwx（2）rwx（3）
  1：所有者 2：所属组 3：其他用户
  r：读
  w：写
  x：执行
  目录：r（可以查看目录内有多少东西）w（可添加、删除和修改目录内东西的熟悉）x（可打开目录）

  文件：r（可以查看文件的具体内容）w（可以添加、删除和修改文件的具体内容，但不能删除文件本身）x（可运行文件，一般都用于可执行文件）
  隐藏权限：SUID（4）、SGID（2）、SBIT（1）
  rws（1、所有者）rws（2、所属组）rwt（3、其他用户）
  1：即使不是文件所有者也可以暂时拥有文件所有者的权利
  2、在拥有这个属性的目录内创建的东西，所属组都属于这个目录的所属组，与东西的创建者无关
  3、在拥有这个属性的目录内创建的东西，除了root和创建者本身，谁都不能删
  在chmod时，隐藏权限写在第一位。



```
取得文件或目录名
[root@study ~]# basename /etc/sysconfig/network
network <== 很简单！就取得最后的档名～
[root@study ~]# dirname /etc/sysconfig/network
/etc/sysconfig <== 取得的变成目录名了！

文件查阅
  cat 由第一行开始显示文件内容
 tac 从最后一行开始显示，可以看出 tac 是 cat 的倒着写！
 nl 显示的时候，顺道输出行号！
 more 一页一页的显示文件内容
 less 与 more 类似，但是比 more 更好的是，他可以往前翻页！
 head 只看头几行 -n+指定行数（正数代表前面，负数代表不输出后面多少行
 tail 只看尾巴几行
 od 以二进制的方式读取文件内容
```



/etc/：几乎系统的所有配置文件案均在此，尤其 passwd,shadow
 /boot：开机配置文件，也是预设摆放核心 vmlinuz 的地方
 /usr/bin, /bin：一般执行档摆放的地方
 /usr/sbin, /sbin：系统管理员常用指令集
/dev：摆放所有系统装置文件的目录
 /var/log：摆放系统注册表文件的地方
 /run：CentOS 7 以后才有，将经常变动的项目(每次开机都不同，如程序的 PID)移动到内存暂存，所以 /run 并不占实际磁盘容量

usr 是 Unix Software Resource 的缩写， 也就是『Unix 操作系统软件资源』所放置的目录，而不是用户的数据啦！这点要注意。 FHS 建议所有软件开发者，应该将他们的数据合理的分别放置到这个目录下的次目录，而不要自行建立该软件自己独立的目录。

* FHS 225页


* 权限

1. 第一个字符代表这个文件是『目录、文件或链接文件等等』：

 当为[ d ]则是目录，例如上表档名为『.config』的那一行；
 当为[ - ]则是文件，例如上表档名为『initial-setup-ks.cfg』那一行；
 若是[ l ]则表示为连结档(link file)；
 若是[ b ]则表示为装置文件里面的可供储存的接口设备(可随机存取装置)；
 若是[ c ]则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置

文件是实际含有数据的地方，包括一般文本文件、数据库内容文件、二进制可执行文件(binary program)等等。 因此，权限对于文件来说，他的意义是这样的：

**r (read)：可读取此一文件的实际内容，如读取文本文件的文字内容等；**

 **w (write)：可以编辑、新增或者是修改该文件的内容(但不含删除该文件)；**
 x (eXecute)：该文件具有可以被系统执行的权限。

文件名的记录是在目录的 block 当中。 因此在第五章文件与目录的权限说明中**，那么因为文件名是记录在目录的 block 当中**， 因此当我们要读取某个文件时，就务必会经过目录的 inode 与 block ，然后才能够找到那个待读取文件的 inode 号码，最终才会读到正确的文件的 block 内的数据。

* chmod

```
从之前的介绍中我们可以发现，基本上就九个权限分别是(1)user (2)group (3)others 三种身份啦！那么我们就可以藉由 u, g, o 来代表三种身份的权限！此外， a 则代表 all 亦即全部
的身份！那么读写的权限就可以写成 r, w, x 啰！
文件或目录

假如我们要『设定』一个文件的权限成为『-rwxr-xr-x』时，基本上就是：
o user (u)：具有可读、可写、可执行的权限；
o group 与 others (g/o)：具有可读与执行的权限。
所以就是：
[root@study ~]# chmod u=rwx,go=rx .bashrc
# 注意喔！那个 u=rwx,go=rx 是连在一起的，中间并没有任何空格符！
```



因为，要读一个文件时，你得要具有『这个文件所在目录的 x 权限』才行！所以，通常要开放的目录， 至少会具备 rx 这两个权限



一、让用户能进入某目录成为『可工作目录』的基本权限为何：
 可使用的指令：例如 cd 等变换工作目录的指令；
 目录所需权限：用户对这个目录至少需要具有 x 的权限
 额外需求：如果用户想要在这个目录内利用 ls 查阅文件名，则用户对此目录还需要 r 的权限。

二、用户在某个目录内读取一个文件的基本权限为何？
 可使用的指令：例如本章谈到的 cat, more, less 等等
 目录所需权限：用户对这个目录至少需要具有 x 权限；
 文件所需权限：使用者对文件至少需要具有 r 的权限才行！

三、让使用者可以修改一个文件的基本权限为何？
 可使用的指令：例如 nano 或未来要介绍的 vi 编辑器等；
 目录所需权限：用户在该文件所在的目录至少要有 x 权限；
 文件所需权限：使用者对该文件至少要有 r, w 权限

四、让一个使用者可以建立一个文件的基本权限为何？
 目录所需权限：用户在该目录要具有 w,x 的权限，重点在 w 啦！

五、让用户进入某目录并执行该目录下的某个指令之基本权限为何？
 目录所需权限：用户在该目录至少要有 x 的权限；

 文件所需权限：使用者在该文件至少需要有 x 的权限



- 实体链接

  使用 ln 如果不加任何参数的话，那么就是 Hard Link 啰！如同范例二的情况，增加了 hard
  link 之后，可以发现使用 ls -l 时，显示的 link 那一栏属性增加了！而如果这个时候砍掉 passwd 会发生什么事情呢？passwd-hd（硬） 的内容还是会跟原来 passwd 相同，但是 passwd-so（软） 就会找不到该文件啦！

  而如果 ln 使用 -s 的参数时，就做成差不多是 Windows 底下的『快捷方式』的意思。当你修改 Linux下的 symbolic link 文件时，则更动的其实是『原始档』， 所以不论你的这个原始档被连结到哪里去，只要你修改了连结档，原始档就跟着变啰！ 以上面为例，由于你使用 -s 的参数建立一个名为passwd-so 的文件，则你修改 passwd-so 时，其内容与 passwd 完全相同，并且，当你按下储存之后，被改变的将是 passwd 这个文件！

## 文件系统

假设我们想要新增一个文件，此时文件系统的行为是：

1. 先确定用户对于欲新增文件的目录是否具有 w 与 x 的权限，若有的话才能新增；
2. 根据 inode bitmap 找到没有使用的 inode 号码，并将新文件的权限/属性写入；
3. 根据 block bitmap 找到没有使用中的 block 号码，并将实际的数据写入 block 中，且更新 inode 的 block
  指向数据；
4. 将刚刚写入的 inode 与 block 数据同步更新 inode bitmap 与 block bitmap，并更新 superblock 的内容。
5. 我们将 inode table 与 data block 称为数据存放区域，至于其他例如 superblock、 block
   bitmap 与 inode bitmap 等区段就被称为 metadata (中介资料) 啰，因为 superblock, inode bitmap 及block bitmap 的数据是经常变动的，每次新增、移除、编辑时都可能会影响到这三个部分的数据，因此才被称为中介数据的啦

- 日志系统

为了避免上述提到的文件系统不一致的情况发生，因此我们的前辈们想到一个方式， 如果在我们的filesystem 当中规划出一个区块，该区块专门在记录写入或修订文件时的步骤， 那不就可以简化一致性检查的步骤了？也就是说：

1. 预备：当系统要写入一个文件时，会先在日志记录区块中纪录某个文件准备要写入的信息；
2. 实际写入：开始写入文件的权限与数据；开始更新 metadata 的数据；
3. 结束：完成数据与 metadata 的更新后，在日志记录区块当中完成该文件的纪录。
  在这样的程序当中，万一数据的纪录过程当中发生了问题，那么我们的系统只要去检查日志记录区块，
  就可以知道哪个文件发生了问题，针对该问题来做一致性的检查即可，而不必针对整块 filesystem 去
  检查， 这样就可以达到快速修复 filesystem 的能力了！这就是日志式文件最基础的功能啰～

- 文件系统的运作

问题：我们现在知道了目录树与文件系统的关系了，但是由第零章的内容我们也知道， 所有的数据都得要加载到内存后 CPU 才能够对该数据进行处理。想一想，如果你常常编辑一个好大的文件， 在编辑的过程中又频繁的要系统来写入到磁盘中，由于磁盘写入的速度要比内存慢很多， 因此你会常常耗在等待磁盘的写入/读取上。真没效率！

解决：异步处理

为了解决这个效率的问题，因此我们的 Linux 使用的方式是透过一个称为异步处理 (asynchronously)的方式。所谓的异步处理是这样的：

当系统加载一个文件到内存后，如果该文件没有被更动过，则在内存区段的文件数据会被设定为干净(clean)的。 但如果内存中的文件数据被更改过了(例如你用 nano 去编辑过这个文件)，此时该内存中的数据会被设定为脏的 (Dirty)。此时所有的动作都还在内存中执行，并没有写入到磁盘中！ 系统会不定时的将内存中设定为『Dirty』的数据写回磁盘，以保持磁盘与内存数据的一致性。 你也可以利用第四章谈到的 sync 指令来手动强迫写入磁盘。

我们知道内存的速度要比磁盘快的多，因此如果能够将常用的文件放置到内存当中，这不就会增加系统性能吗？ 没错！是有这样的想法！因此我们 Linux 系统上面文件系统与内存有非常大的关系喔：
 系统会将常用的文件数据放置到主存储器的缓冲区，以加速文件系统的读/写；
 承上，因此 Linux 的物理内存最后都会被用光！这是正常的情况！可加速系统效能；
 你可以手动使用 sync 来强迫内存中设定为 Dirty 的文件回写到磁盘中；
 若正常关机时，关机指令会主动呼叫 sync 来将内存的数据回写入磁盘内；
 但若不正常关机(如跳电、当机或其他不明原因)，由于数据尚未回写到磁盘内， 因此重新启动后可能会花很多时间在进行磁盘检验，甚至可能导致文件系统的损毁(非磁盘损毁)。



**将文件系统与目录树结合的动作我们称为『挂载』。**  **重点是：挂载点一定是目录，该目录为进入该文件系统的入口。** 因此并不是你有任何文件系统都能使用，必须要『挂载』到目录树的某个目录后，才能够使用该文件系统的。

- **情境模拟题二**：由于我的系统原本分区的不够好，我的用户希望能够独立一个 filesystem 附挂在

/srv/myproject 目录下。 那你该如何建立新的 filesystem ，并且让这个 filesystem 每次开机都能够自动的挂载到 /srv/myproject ， 且该目录是给 project 这个群组共享的，其他人不可具有任何权限。且该 filesystem具有 1GB 的容量。
o 目标：理解文件系统的建置、自动挂载文件系统与项目开发必须要的权限；
o 前提：你需要进行过第六章的情境模拟才可以继续本章；
o 需求：本章的所有概念必须要清楚！
那就让我们开始来处理这个流程吧！

1. 首先，我们必须要使用 gdisk /dev/vda 来建立新的 partition。 然后按下『 n 』，按下『Enter』选择默认的分区槽号码，再按『Enter』选择预设的启始磁柱， 按下『+1G』建立 1GB 的磁盘分区槽，再按下『Enter』选择预设的文件系统 ID。 可以多按一次『p 』看看是否正确，若无问题则按下『w』写入分区表；
2. 避免重新启动，因此使用『 partprobe 』强制核心更新分区表；
3. 建立完毕后，开始进行格式化的动作如下：『mkfs.xfs -f /dev/vda4』，这样就 OK 了！
4. 开始建立挂载点，利用：『 mkdir /srv/myproject 』来建立即可；
5. 编写自动挂载的配置文件：『 nano /etc/fstab 』，这个文件最底下新增一行，内容如下：
  /dev/vda4 /srv/myproject xfs defaults 0 0
6. 测试自动挂载：『 mount -a 』，然后使用『 df /srv/myproject 』观察看看有无挂载即可！
7. 设定最后的权限，使用：『 chgrp project /srv/myproject 』以及『 chmod 2770 /srv/myproject 』即可。

##查找

* 搜索指令的完整地址 which
* 搜索文件用 whereis (只搜索特定目录，find是全盘)   whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息
* locate  查找出文件地址，数量，只在特定数据库内查

[root@study ~]# **whereis [- - bmsu]** 文件 或目 录 名
选项与参数：
-l :可以列出 whereis 会去查询的几个主要目录而已
-b :只找 binary 格式的文件
-m :只找在说明文件 manual 路径下的文件
-s :只找 source 来源文件
-u :搜寻不在上述三个项目当中的其他特殊文件

- find

[root@study ~]# find [PATH] [option] [action]
选项与参数：

1. 与时间有关的选项：共有 -atime, -ctime 与 -mtime ，以 -mtime 说明
  -mtime n ：n 为数字，意义为在 n 天之前的『一天之内』被更动过内容的文件；
  -mtime +n ：列出在 n 天之前(不含 n 天本身)被更动过内容的文件档名；
  -mtime -n ：列出在 n 天之内(含 n 天本身)被更动过内容的文件档名。
  -newer file ：file 为一个存在的文件，列出比 file 还要新的文件档名

2.  modification time (mtime)：
  当该文件的『内容数据』变更时，就会更新这个时间！内容数据指的是文件的内容，而不是文件的属性或权限喔！

  status time (ctime)：
  当该文件的『状态 (status)』改变时，就会更新这个时间，举例来说，像是权限与属性被更改了，都会更新这个时间啊。

   access time (atime)：当『该文件的内容被取用』时，就会更新这个读取时间 (access)。举例来说，我们使用 cat 去读取

  /etc/man_db.conf ， 就会更新该文件的 atime 了。


## 压缩

- tar

将多个文件或目录压缩到一个文件

其实最简单的使用 tar 就只要记忆底下的方式即可：
 压 缩：tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称
 查 询：tar -jtv -f filename.tar.bz2
 解压缩：tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录

那个 filename.tar.bz2 是我们自己取的档名，tar 并不会主动的产生建立的档名喔！我们要自定义啦！所以扩展名就显的很重要了！如果不加 [-z|-j|-J] 的话，档名最好取为 *.tar 即可。如果是 -j 选项，代表有 bzip2 的支持，因此档名最好就取为 *.tar.bz2 ，因为 bzip2 会产生 .bz2 的扩展名之故！ 至于如果是加上了 -z 的 gzip 的支持，那档名最好取为 *.tar.gz 喔！了解乎？

**仅解开单一 文件 的方法**

```

刚刚上头我们解压缩都是将整个打包文件的内容全部解开！想象一个情况，如果我只想要解开打包文
件内的其中一个文件而已， 那该如何做呢？很简单的，你只要使用 -jtv 找到你要的档名，然后将该档名解开即可。 我们用底下的例子来说明一下：
# 1. 先找到我们要的档名，假设解开 shadow 文件好了：
[root@study ~]# tar - - jtv - - f /root/etc.tar.bz2 | grep 'shadow'
---------- root/root 721 2015-06-17 00:20 etc/gshadow
---------- root/root 1183 2015-06-17 00:20 etc/shadow-
---------- root/root 1210 2015-06-17 00:20 etc/shadow <==这是我们要的！
---------- root/root 707 2015-06-17 00:20 etc/gshadow-
# 先搜寻重要的档名！其中那个 grep 是『撷取』关键词的功能！我们会在第三篇说明！
# 这里您先有个概念即可！那个管线 | 配合 grep 可以撷取关键词的意思！

# 2. 将该文件解开！语法与实际作法如下：
[root@study ~]# tar - - jxv - - f 打包檔 .tar.bz2 待解 开档 名
[root@study ~]# tar - - jxv - - f  /root/etc.tar.bz2   etc/shadow
etc/shadow
[root@study ~]# ll etc
total 4
----------. 1 root root 1210 Jun 17 00:20 shadow
# 很有趣！此时只会解开一个文件而已！不过，重点是那个档名！你要找到正确的档名。
# 在本例中，你不能写成 /etc/shadow ！因为记录在 etc.tar.bz2 内的并没有 / 之故！

```

**打包某目录，但不含该目录下的某些 文件 之作法**
假设我们想要打包 /etc/ /root 这几个重要的目录，但却不想要打包 /root/etc* 开头的文件，因为该文件都是刚刚我们才建立的备份档嘛！ 而且假设这个新的打包文件要放置成为 /root/system.tar.bz2 ，当然这个文件自己不要打包自己 (因为这个文件放置在 /root 底下啊！)，此时我们可以透过 --exclude的帮忙！ 那个 exclude 就是不包含的意思！所以你可以这样做：
[root@study ~]# tar - - jcv - - f /root/system.tar.bz2 -- exclude=/root/etc* \ 

exclude=/root/system.tar.bz2 /etc /root

上面的指令是一整列的～其实你可以打成：『tar -jcv -f /root/system.tar.bz2 --exclude=/root/etc* --exclude=/root/system.tar.bz2 /etc /root』，如果想要两行输入时，最后面加上反斜杠 (\) 并立刻按下[enter] ， 就能够到第二行继续输入了。



- gzip 可以说是应用度最广的压缩指令了！目前 gzip 可以解开 compress, zip 与 gzip 等软件所压缩

的文件。 至于 gzip 所建立的压缩文件为 *.gz 的檔名喔！让我们来看看这个指令的语法吧：

```
[dmtsai@study ~]$ gzip [- cdtv#] 檔名

[dmtsai@study ~]$ zcat 檔名 .gz

```

选项与参数：
-c ：将压缩的数据输出到屏幕上，可透过数据流重导向来处理；
-d ：解压缩的参数；
-t ：可以用来检验一个压缩文件的一致性～看看文件有无错误；
-v ：可以显示出原文件/压缩文件案的压缩比等信息；
-# ：# 为数字的意思，代表压缩等级，-1 最快，但是压缩比最差、-9 最慢，但是压缩比最好！预设是 -6

当你使用 gzip 进行压缩时，在预设的状态下原本的文件会被压缩成为 .gz 的档名，**源文件就不再存在了。** 这点与一般习惯使用 windows 做压缩的朋友所熟悉的情况不同喔！要注意！要注意！ 此外，使用 gzip 压缩的文件在 Windows 系统中，竟然可以被 WinRAR/7zip 这个软件解压缩呢！很好用吧！

与 gzip 相反， gzip -d 会将原本的 .gz 删除，回复到原本的 services 文件。



- bzip2比gzip更好用

[dmtsai@study ~]$ bzip2 [- - cdkzv#] 檔名

[dmtsai@study ~]$ bzcat 檔名 .bz2
选项与参数：
-c ：将压缩的过程产生的数据输出到屏幕上！
-d ：解压缩的参数
-k ：保留源文件，而不会删除原始的文件喔！
-z ：压缩的参数 (默认值，可以不加)
-v ：可以显示出原文件/压缩文件案的压缩比等信息；
-# ：与 gzip 同样的，都是在计算压缩比的参数， -9 最佳， -1 最快！

## 磁盘状态

- lsblk 可以看成『 list block device 』的缩写，就是列出所有储存装置的意思！
- lkid 列出装置的 UUID 等参数
  使用 blkid 来找出装置的 UUID 喔！ 什么是 UUID 呢？UUID 是全局单一标识符 (universally
  unique identifier)，Linux 会将系统内所有的装置都给予一个独一无二的标识符， 这个标识符就可以拿来作为挂载或者是使用这个装置/文件系统之用了。
- parted 列出磁盘的 分区 表类型与 分区 信息
  虽然我们已经知道了系统上面的所有装置，并且透过 blkid 也知道了所有的文件系统！不过，还是不清楚磁盘的分区类型。 
- 『MBR 分区表请使用 fdisk 分区， **GPT 分区表请使用 gdisk 分区！**』
- partprobe 更新 Linux 核心的 分区 参数-s就可以
- 我们常听到的『格式化』其实应该称为『建置文件系统 (make filesystem)』才对啦！所以使用的指令是 mkfs 喔！那我们要建立的其实是 xfs 文件系统， 因此使用的是 mkfs.xfs 这个指令才对。这个指令是这样使用的：
  [root@study ~]# mkfs.xfs [- - b bsize][- - d parms] [- - i parms][ [- - l parms] [- - L label][- - f] \ [ [- - r parms] 装 置名 称
  ​

# HTTP

俗话说得好，不懂前端的Python工程师不是好的产品经理。有Web开发经验的同学都明白，Web App最复杂的部分就在HTML页面。HTML不仅要正确，还要通过CSS美化，再加上复杂的JavaScript脚本来实现各种交互和动画效果。总之，生成HTML页面的难度很大。

使用 HTTP 协议，每当有新的请求发送时，就会有对应的新响应产生。协议本身并不保留之前一切的请求或响应报文的信息。这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计成如此简单的。

可是，随着 Web 的不断发展，因无状态而导致业务处理变得棘手的情况增多了。比如，用户登录到一家购物网站，即使他跳转到该站的其他页面后，也需要能继续保持登录状态。针对这个实例，网站为了能够掌握是谁送出的请求，需要保存用户的状态。

HTTP/1.1 虽然是无状态协议，但为了实现期望的保持状态功能，于是引入了 Cookie 技术。有了 **Cookie 再用 HTTP 协议通信，就可以管理状态了。**

Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服务器端发送的响应报文内的一个叫做 **Set-Cookie 的首部字段信息，通知客户端保存 Cookie**。

当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。

##告知服务器意图

- GET 方法用来请求访问已被 URI 识别的资源。指定的资源经服务器端解析后返回响应内容。也就是说，如果请求的资源是文本，那就保持原样返回；如果是像 CGI（Common Gateway Interface，通用网关接口）那样的程序，则返回经过执行后的输出结果。

- POST 方法用来传输实体的主体（各种处理结果）。虽然用 GET 方法也可以传输实体的主体，但一般不用 GET 方法进行传输，而是用 POST 方法。虽说 POST 的功能与 GET 很相似，但 POST 的主要目的并不是获取响应的主体内容。

- PUT 方法用来传输文件。就像 FTP 协议的文件上传一样，要求在请求报文的主体中包含文件内容，然后保存到请求 URI 指定的位置。

  但是，鉴于 HTTP/1.1 的 PUT 方法自身不带验证机制，任何人都可以上传文件 , 存在安全性问题，因此一般的 Web 网站不使用该方法。若配合 Web 应用程序的验证机制，或架构设计采用 REST（REpresentational State Transfer，表征状态转移）标准的同类 Web 网站，就可能会开放使用 PUT 方法。

- HEAD：获得报文首部

  HEAD 方法和 GET 方法一样，只是不返回报文主体部分。用于确认 URI 的有效性及资源更新的日期时间等。

- DELETE：删除文件

  DELETE 方法用来删除文件，是与 PUT 相反的方法。DELETE 方法按请求 URI 删除指定的资源。

- OPTIONS：询问支持的方法

  OPTIONS 方法用来查询针对请求 URI 指定的资源支持的方法。

- TRACE：追踪路径

  TRACE 方法是让 Web 服务器端将之前的请求通信环回给客户端的方法。

  发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器端就将该数字减 1，当数值刚好减到 0 时，就停止继续传输，最后接收到请求的服务器端则返回状态码 200 OK 的响应。

  客户端通过 TRACE 方法可以查询发送出去的请求是怎样被加工修改 / 篡改的。这是因为，请求想要连接到源目标服务器可能会通过代理中转，TRACE 方法就是用来确认连接过程中发生的一系列操作。

  但是，TRACE 方法本来就不怎么常用，再加上它容易引发 XST（Cross-Site Tracing，跨站追踪）攻击，通常就更不会用到了。

- CONNECT：要求用隧道协议连接代理

  CONNECT 方法要求在与代理服务器通信时建立隧道，实现用隧道协议进行 TCP 通信。主要使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加 密后经网络隧道传输



## 服务器 状态码

表 4-1：状态码的类别

  	  类别 	  原因短语 
 1XX 	 Informational（信息性状态码） 	 接收的请求正在处理 
 2XX 	 Success		（成功状态码） 		 请求正常处理完毕 
 3XX 	 Redirection（重定向状态码） 		 需要进行附加操作以完成请求 
 4XX 	 Client Error（客户端错误状态码） 	 服务器无法处理请求 
 5XX 	 Server Error（服务器错误状态码） 	 服务器处理请求出错



## html

- <html> 与 </html> 之间的文本描述网页
- <body> 与 </body> 之间的文本是可见的页面内容
- <h1> 与 </h1> 之间的文本被显示为标题
- <p> 与 </p> 之间的文本被显示为段落

# Git

查看文件内容是cat 文件名

简单解释一下 git commit 命令， -m 后面输入的是本次提交的说明，可以输入任意内容，当然最好是有意义的，这样你就能从历史记录里方便地找到改动记录。

初始化一个Git仓库，使用 git init 命令。当你本地创建了一个工作目录，你可以进入这个目录，使用'git init'命令进行初始化
添加文件到Git仓库，分两步：
第一步，使用命令 git add &lt;file&gt; ，注意，可反复多次使用，添加多个文件；
第二步，使用命令 git commit ，完成。查看commit 历史：git log --pretty=oneline --abbrev-commit

git status 命令可以让我们时刻掌握仓库当前的状态

git diff 顾名思义就是查看difference，显示的格式正是Unix通用的diff格式，可以从上面的命令输出看到，我们在第一行添加了一个“distributed”单词；**如果 git status 告诉你有文件被修改过，用 git diff 可以查看修改内容。**

git reset 命令 返回上一个版本，有对应的版本号也可以返回

在Git中，总是有后悔药可以吃的。当你用 $ git reset --hard HEAD^ 回退到 add distributed 版本时，再想恢复到 append GPL ，就必须找到 appendGPL 的commit id。Git提供了一个命令 git reflog 用来记录你的每一次命令

HEAD 指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令 git reset --hard commit_id 。

* 穿梭前，用 git log 可以查看提交历史，以便确定要回退到哪个版本。
* 要重返未来，用 git reflog 查看命令历史，以便确定要回到未来的哪个版本。

工作区（Working Directory）
就是你在电脑里能看到的目录，比如我的 learngit 文件夹就是一个工作区：



## 版本库（Repository）

工作区有一个隐藏目录 .git ，这个不算工作区，而是Git的版本库。版本库里面有暂存库

Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支 master ，以及指向 master 的一个指针叫 HEAD 

修改后需要git add 然后在commit 才能记录下来。



## git 跟踪文件



Git跟踪并管理的是修改，而非文件。

命令 git checkout -- readme.txt 意思就是，把 readme.txt 文件在工作区的修改全部撤销，这里有两种情况：

* 一种是 readme.txt 自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态；
* 一种是 readme.txt 已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。

总之，就是让这个文件回到最近一次 git commit 或 git add 时的状态。git checkout -- file 命令中的 -- 很重要，没有 -- ，就变成了“切换到另一个分支”的命令，我们在后面的分支管理中会再次遇到 git checkout 命令。



$ rm test.txt
这个时候，Git知道你删除了文件，因此，工作区和版本库就不一致了， git status 命令会立刻告诉你哪些文件被删除了。现在你有两个选择，

* 一是确实要从版本库中删除该文件，那就用命令 git rm 删掉，并且 git commit ：

```
$ git rm test.txt
rm 'test.txt'
$ git commit -m "remove test.txt"
```



* 另一种情况是删错了，因为版本库里还有呢，所以可以很轻松地把误删的文件恢复
  到最新版本：
  $ git checkout -- test.txt
  git checkout 其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。


##远程仓库 

```
git remote add origin git@github.com:michaelliao/learngit.git 本地关联远程仓库

git push -u origin master 推送

git push origin master 以后就可以用这条命令推送，就表示能把最新的分支推送上去
```

把本地库的内容推送到远程，用 git push 命令，实际上是把当前分支 master 推送到远程。
由于远程库是空的，我们第一次推送 master 分支时，加上了 -u 参数，Git不但会把本地的 master 分支内容推送的远程新的 master 分支，还会把本地的 master 分支和远程的 master 分支关联起来，在以后的推送或者拉取时就可以简化命令。
推送成功后，可以立刻在GitHub页面中看到远程库的内容已经和本地一模一样

## **分支管理**

属于你自己的分支，别人看不见，当完成的时候再合并到正式的文件里面。主线叫master，分支会延伸出去，最后分支和master合并，指针也剩下master的。

Git鼓励大量使用分支：
查看分支： git branch
创建分支： git branch &lt;name&gt;
切换分支： git checkout &lt;name&gt;
创建+切换分支： git checkout -b &lt;name&gt;
合并某分支到当前分支： git merge &lt;name&gt;
删除分支： git branch -d &lt;name&gt;



当出现分支，主线也写出了分支，合并的时候出问题需要手动修改；

用 git log 看看分支历史：

准备合并 dev 分支，请注意 --no-ff 参数，表示禁用 Fast forward ：
$ git merge --no-ff -m "merge with no-ff" dev

合并后，我们用 git log 看看分支历史：
$ git log --graph --pretty=oneline --abbrev-commit

合并分支时，加上 --no-ff 参数就可以用普通模式合并，合并后的历史有分支，
能看出来曾经做过合并，而 fast forward 合并就看不出来曾经做过合并。



##**改bug**

并不是你不想提交，而是工作只进行到一半，还没法提交，预计完成还需1天时间。但是，必须在两个小时内修复该bug，怎么办？幸好，Git还提供了一个 stash 功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作：

$ git stash

Saved working directory and index state WIP on dev: 6224937 add merge

HEAD is now at 6224937 add merge

工作区是干净的，刚才的工作现场存到哪去了？用 git stash list 命令看看：

工作现场还在，Git把stash内容存在某个地方了，但是需要恢复一下，有两个办法：

* 一是用 git stash apply 恢复，但是恢复后，stash内容并不删除，你需要用 git stash drop 来删除；
* 另一种方式是用 git stash pop ，恢复的同时把stash内容也删了：

你可以多次stash，恢复的时候，先用 git stash list 查看，然后恢复指定的stash，用命令：
$ git stash apply stash@{0}

* feature分支

当你需要增加功能的时候，可以新建一个分支，如果有必要就合并上传，没必要就删除

##多人协作

当你从远程仓库克隆时，实际上Git自动把本地的 master 分支和远程的 master 分支对应起来了，并且，远程仓库的默认名称是 origin 。要查看远程库的信息，用 git remote ：

```
$ git remote

origi
```

用 git remote -v 显示更详细的信息



因此，多人协作的工作模式通常是这样：

1. 首先，可以试图用 git push origin branch-name 推送自己的修改；
2. 如果推送失败，则因为远程分支比你的本地更新，需要先用 git pull 试图合
  并；
3. 如果合并有冲突，则解决冲突，并在本地提交；
4. 没有冲突或者解决掉冲突后，再用 git push origin branch-name 推送就
  能成功！
  如果 git pull 提示“no tracking information”，则说明本地分支和远程分支的链接
  关系没有创建，用命令 git branch --set-upstream branch-name
  origin/branch-name 。
  这就是多人协作的工作模式，一旦熟悉了，就非常简单。



小结
查看远程库信息，使用 git remote -v ；
本地新建的分支如果不推送到远程，对其他人就是不可见的；
从本地推送分支，使用 git push origin branch-name ，如果推送失败，先用 git pull 抓取远程的新提交；
在本地创建和远程分支对应的分支，使用 git checkout -b branch-name origin/branch-name ，本地和远程分支的名称最好一致；
建立本地分支和远程分支的关联，使用 git branch --set-upstream branch-name origin/branch-name ；从远程抓取分支，使用 git pull ，如果有冲突，要先处理冲突。

## 标签管理



发布一个版本时，我们通常先在版本库中打一个标签，这样，就唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以，标签也是版本库的一个快照。Git的标签虽然是版本库的快照，但其实它就是指向某个commit的指针（跟分支很像对不对？但是分支可以移动，标签不能移动），所以，创建和删除标签都是瞬间
完成的。

git tag tag_name 新建当前版本标签

git tag 查看便签

标签不是按时间顺序列出，而是按字母排序的。可以用 git show&lt;tagname&gt; 查看标签信息：

$ git show v0.9

还可以创建带有说明的标签，用 -a 指定标签名， -m 指定说明文字：
$ git tag -a v0.1 -m "version 0.1 released" 3628164

用命令 git show &lt;tagname&gt; 可以看到说明文字：



命令 git tag &lt;name&gt; 用于新建一个标签，默认为 HEAD ，也可以指定一个commit id；
git tag -a &lt;tagname&gt; -m "blablabla..." 可以指定标签信息；
git tag -s &lt;tagname&gt; -m "blablabla..." 可以用PGP签名标签；
命令 git tag 可以查看所有标签。



* **标签删除**

如果标签打错了，也可以删除：

```
$ git tag -d v0.1

Deleted tag 'v0.1' (was e078af9)

```



因为创建的标签都只存储在本地，不会自动推送到远程。所以，打错的标签可以在本地安全删除。
如果要推送某个标签到远程，使用命令 git push origin &lt;tagname&gt; ：
$ git push origin v1.0

或者，一次性推送全部尚未推送到远程的本地标签：
$ git push origin --tags



如果标签已经推送到远程，要删除远程标签就麻烦一点，先从本地删除：
$ git tag -d v0.9
Deleted tag 'v0.9' (was 6224937)

然后，从远程删除。删除命令也是push，但是格式如下：
$ git push origin :refs/tags/v0.9
To git@github.com:michaelliao/learngit.git

要看看是否真的从远程库删除了标签，可以登陆GitHub查看。

**小结**
命令 git push origin &lt;tagname&gt; 可以推送一个本地标签；
命令 git push origin --tags 可以推送全部未推送过的本地标签；
命令 git tag -d &lt;tagname&gt; 可以删除一个本地标签；
命令 git push origin :refs/tags/&lt;tagname&gt; 可以删除一个远程标签。



